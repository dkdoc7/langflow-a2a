import json
import asyncio
from typing import List, Dict, Any, Optional
import aiohttp
from uuid import uuid4
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.tools import StructuredTool

from langflow.base.agents.agent import LCToolsAgentComponent
from langflow.base.agents.events import ExceptionWithMessageError
from langflow.base.models.model_input_constants import (
    ALL_PROVIDER_FIELDS,
    MODEL_DYNAMIC_UPDATE_FIELDS,
    MODEL_PROVIDERS,
    MODEL_PROVIDERS_DICT,
    MODELS_METADATA,
)
from langflow.base.models.model_utils import get_model_name
from langflow.components.helpers.current_date import CurrentDateComponent
from langflow.components.helpers.memory import MemoryComponent
from langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent
from langflow.custom.custom_component.component import _get_component_toolkit
from langflow.custom.utils import update_component_build_config
from langflow.field_typing import Tool
from langflow.io import BoolInput, DropdownInput, HandleInput, IntInput, MultilineInput, Output, StrInput
from langflow.logging import logger
from langflow.schema.dotdict import dotdict
from langflow.schema.message import Message
from langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI


def create_prompt_from_component(prompt_component, default_system_message: str = "") -> ChatPromptTemplate:
    """
    í”„ë¡¬í”„íŠ¸ ì»´í¬ë„ŒíŠ¸ì—ì„œ ChatPromptTemplateì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        prompt_component: Langflow Prompt Componentì—ì„œ ì¶œë ¥ëœ Message ê°ì²´
        default_system_message: ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€
    
    Returns:
        ChatPromptTemplate: LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    """
    if not prompt_component:
        logger.warning("prompt_component is None or empty")
        return None
        
    try:
        # Message ê°ì²´ì—ì„œ template ì¶”ì¶œ
        if hasattr(prompt_component, 'template'):
            template_content = prompt_component.template
        elif hasattr(prompt_component, 'text'):
            template_content = prompt_component.text
        else:
            logger.warning("Prompt component format not recognized")
            return None
        
        # ChatPromptTemplate ìƒì„± (ë³€ìˆ˜ëŠ” ëŸ°íƒ€ìž„ì— ì£¼ìž…)
        # chat_history ë³€ìˆ˜ê°€ í¬í•¨ëœ ê²½ìš° MessagesPlaceholder ì¶”ê°€
        if "{chat_history}" in template_content:
            if default_system_message:
                return ChatPromptTemplate.from_messages([
                    ("system", default_system_message),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("human", template_content)
                ])
            else:
                return ChatPromptTemplate.from_messages([
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("human", template_content)
                ])
        else:
            if default_system_message:
                return ChatPromptTemplate.from_messages([
                    ("system", default_system_message),
                    ("human", template_content)
                ])
            else:
                return ChatPromptTemplate.from_messages([
                    ("human", template_content)
                ])
            
    except Exception as e:
        logger.error(f"Error creating prompt from component: {e}")
        return None


def set_advanced_true(component_input):
    component_input.advanced = True
    return component_input


MODEL_PROVIDERS_LIST = ["Anthropic", "Google Generative AI", "Groq", "OpenAI"]


class A2APlannerComponent(ToolCallingAgentComponent):
    display_name: str = "A2A Planner"
    description: str = "A2A Discovery ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ì—¬ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  ìž‘ì—… ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” í”Œëž˜ë„ˆ"
    documentation: str = "https://docs.langflow.org/agents"
    icon = "bot"
    beta = False
    name = "A2A Planner"

    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]

    inputs = [
        # LLM ì—°ê²°ì„ ìœ„í•œ ìž…ë ¥ í•„ë“œ
        DropdownInput(
            name="agent_llm",
            display_name="Model Provider",
            info="The provider of the language model that the agent will use to generate responses.",
            options=[*MODEL_PROVIDERS_LIST, "Custom"],
            value="OpenAI",
            real_time_refresh=True,
            input_types=["LanguageModel"],
            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST] + [{"icon": "brain"}],
        ),
        # OpenAI ëª¨ë¸ ì„¤ì • ìž…ë ¥ë“¤
        *MODEL_PROVIDERS_DICT["OpenAI"]["inputs"],

        StrInput(
            name="a2a_api_base",
            display_name="A2A API Base URL",
            info="A2A Discovery ì„œë¹„ìŠ¤ì˜ API ê¸°ë³¸ URL (ì˜ˆ: http://localhost:8000, https://api.example.com)",
            value="http://localhost:8000",
            advanced=False,
        ),

        IntInput(
            name="n_messages",
            display_name="Number of Chat History Messages",
            value=100,
            info="Number of chat history messages to retrieve.",
            advanced=True,
            show=True,
        ),
        # ChatInput ì—°ê²°ì„ ìœ„í•œ ìž…ë ¥ í•„ë“œ
        StrInput(
            name="input_value",
            display_name="Input Value",
            info="ì‚¬ìš©ìž ìž…ë ¥ ë©”ì‹œì§€ ë˜ëŠ” ChatInputì—ì„œ ì—°ê²°ëœ ê°’",
            value="",
            advanced=False,
            input_types=["Message"],
        ),
        # Agent Description ìž…ë ¥ í•„ë“œ
        StrInput(
            name="agent_description",
            display_name="Agent Description",
            info="ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì„¤ëª…",
            value="A helpful assistant with access to the following tools:",
            advanced=True,
        ),
        # ê¸°ë³¸ ì—ì´ì „íŠ¸ ìž…ë ¥ë“¤ (max_iterations ì œì™¸)
        BoolInput(
            name="handle_parsing_errors",
            display_name="Handle Parsing Errors",
            value=True,
            info="Whether to handle parsing errors.",
            advanced=True,
        ),
        BoolInput(
            name="verbose",
            display_name="Verbose",
            value=False,
            info="Whether to run in verbose mode.",
            advanced=True,
        ),
        BoolInput(
            name="add_current_date_tool",
            display_name="Current Date",
            advanced=True,
            info="If true, will add a tool to the agent that returns the current date.",
            value=True,
        ),
        # Prompt Component ìž…ë ¥ í•„ë“œë“¤ (í•„ìˆ˜)
        HandleInput(
            name="system_prompt",
            display_name="System Prompt (í•„ìˆ˜)",
            info="ìž‘ì—… ê³„íš ìˆ˜ë¦½ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Prompt Template ì»´í¬ë„ŒíŠ¸ ì—°ê²° í•„ìˆ˜)",
            advanced=False,
            input_types=["Message"],
            required=True,
        ),
        HandleInput(
            name="tools",
            display_name="Tools",
            input_types=["Tool"],
            is_list=True,
            required=False,
            info="These are the tools that the agent can use to help with tasks.",
        ),
    ]
    outputs = [Output(name="response", display_name="Response", method="message_response")]

    async def message_response(self) -> Message:
        """A2A Plannerì˜ ë©”ì¸ ì‘ë‹µ ë©”ì„œë“œ"""
        logger.info("message_response called - starting A2A Planner execution")

        try:
            # LLM ì´ˆê¸°í™”
            await self._initialize_llm()
            
            # ì‹¤ì œ A2A Planner ë¡œì§ ì‹¤í–‰
            result = await self.run_a2a_planner()
            return result
        except Exception as e:
            logger.error(f"A2A Planner execution error: {e}")
            return Message(
                text=f"A2A Planner ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )

    async def _initialize_llm(self):
        """LLM ë° í•„ìˆ˜ ì†ì„± ì´ˆê¸°í™”"""
        try:
            # chat_history ì´ˆê¸°í™”
            if not hasattr(self, 'chat_history'):
                self.chat_history = []
                logger.info("Initialized empty chat_history")
            
            if hasattr(self, 'llm') and self.llm is not None and not isinstance(self.llm, str):
                logger.info("LLM already initialized")
                return
                
            # agent_llmì´ ì„¤ì •ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¤ì œ LLM ê°ì²´ë¡œ ë³€í™˜
            if hasattr(self, 'agent_llm') and self.agent_llm is not None:
                logger.info(f"Initializing LLM with agent_llm: {type(self.agent_llm)}")
                
                # agent_llmì´ ë¬¸ìžì—´ì¸ ê²½ìš° ì‹¤ì œ LLM ê°ì²´ë¡œ ë³€í™˜
                if isinstance(self.agent_llm, str):
                    logger.info("Converting string agent_llm to actual LLM object")
                    llm_model, display_name = self.get_llm()
                    self.llm = llm_model
                else:
                    # ì´ë¯¸ LLM ê°ì²´ì¸ ê²½ìš°
                    self.llm = self.agent_llm
            else:
                logger.warning("No agent_llm provided, LLM will not be available")
                self.llm = None
                
        except Exception as e:
            logger.error(f"Failed to initialize LLM: {e}")
            self.llm = None

    async def run_a2a_planner(self) -> Message:
        """A2A í”Œëž˜ë„ˆì˜ ë©”ì¸ ì‹¤í–‰ ë¡œì§"""
        try:
            # 1. A2A Discovery ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ
            available_agents = await self.get_available_agents()

            # 2. ìž‘ì—… ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½
            work_plan = await self.create_work_plan(available_agents)

            # 3. ê²°ê³¼ í¬ë§·íŒ… ë° ë°˜í™˜
            result_text = self.format_planner_result(available_agents, work_plan)
            
            return Message(
                text=result_text,
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )

        except Exception as e:
            logger.error(f"Error in A2A planner execution: {e}")
            return Message(
                text=f"A2A í”Œëž˜ë„ˆ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )

    async def get_available_agents(self) -> List[Dict[str, Any]]:
        """A2A Discovery ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ì¡°íšŒ"""
        try:
            api_url = f"{self.a2a_api_base}/agents?status=active"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(api_url) as response:
                    if response.status == 200:
                        response_data = await response.json()
                       
                        # A2A Discovery ì„œë¹„ìŠ¤ëŠ” AgentListResponse í˜•íƒœë¡œ ì‘ë‹µ: {"agents": [...]}
                        if isinstance(response_data, dict) and 'agents' in response_data:
                            agents = response_data['agents']
                            logger.info(f"A2A Discovery : Found {len(agents)} available agents.")
                            return agents
                        else:
                            logger.warning(f"A2A Discovery : Unexpected response format from A2A Discovery service: {type(response_data)}")
                            return []
                    else:
                        logger.warning(f"A2A Discovery : Failed to get agents from A2A Discovery service: {response.status}")
                        return []
        except Exception as e:
            logger.warning(f"A2A Discovery : Error connecting to A2A Discovery service: {e}")
            return []

    async def create_work_plan(self, available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‚¬ìš©ìž ìž‘ì—…ì„ ë¶„ì„í•˜ê³  ìž‘ì—… ë¶„í•  ê³„íšì„ ìˆ˜ë¦½"""
        
        # System Prompt í•„ìˆ˜ ì—°ê²° í™•ì¸
        if not hasattr(self, 'system_prompt') or not self.system_prompt:
            msg = "System Promptê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Prompt Template ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
                
        planning_prompt = create_prompt_from_component(
            self.system_prompt,
            default_system_message=""
        )
        
        if planning_prompt is None:
            msg = "System Prompt ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)

        # OUTPUT_SCHEMA ì •ì˜
        output_schema = {
            "type": "object",
            "properties": {
                "goal": {"type": "string", "description": "ì „ì²´ ëª©í‘œ"},
                "assumptions": {"type": "array", "items": {"type": "string"}, "description": "ê°€ì •ì‚¬í•­ë“¤"},
                "updated": {"type": "boolean", "description": "ê³„íšì´ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€"},
                "work_breakdown": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string", "description": "íƒœìŠ¤í¬ ID (ì˜ˆ: T1, T2)"},
                            "title": {"type": "string", "description": "íƒœìŠ¤í¬ ì œëª©"},
                            "agent": {"type": "string", "description": "ë‹´ë‹¹ ì—ì´ì „íŠ¸ ID ë˜ëŠ” ì´ë¦„"},
                            "skills": {"type": "array", "items": {"type": "string"}, "description": "í•„ìš”í•œ ìŠ¤í‚¬ë“¤"},
                            "inputs": {"type": "array", "items": {"type": "string"}, "description": "ìž…ë ¥ í•­ëª©ë“¤"},
                            "outputs": {"type": "array", "items": {"type": "string"}, "description": "ì¶œë ¥ í•­ëª©ë“¤"},
                            "dod": {"type": "array", "items": {"type": "string"}, "description": "ì™„ë£Œ ê¸°ì¤€(Definition of Done)"},
                            "est_hours": {"type": "number", "description": "ì¶”ì • ì†Œìš” ì‹œê°„(ì‹œê°„ ë‹¨ìœ„)"},
                            "dependencies": {"type": "array", "items": {"type": "string"}, "description": "ì˜ì¡´ì„± íƒœìŠ¤í¬ IDë“¤"},
                            "parallelizable": {"type": "boolean", "description": "ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€"},
                            "risk": {"type": "array", "items": {"type": "string"}, "description": "ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤"},
                            "mitigation": {"type": "array", "items": {"type": "string"}, "description": "ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆë“¤"},
                            "bus": {
                                "type": "object",
                                "properties": {
                                    "use_bus": {"type": "boolean"},
                                    "topics": {"type": "array", "items": {"type": "string"}},
                                    "role": {"type": "string", "enum": ["producer", "consumer", "both"]},
                                    "message_schema": {"type": "object"},
                                    "qos": {"type": "object"},
                                    "contracts": {"type": "array", "items": {"type": "string"}}
                                }
                            }
                        }
                    }
                },
                "critical_path": {"type": "array", "items": {"type": "string"}, "description": "í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤ íƒœìŠ¤í¬ IDë“¤"},
                "execution_plan": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "phase": {"type": "string", "description": "ì‹¤í–‰ ë‹¨ê³„"},
                            "targets": {"type": "array", "items": {"type": "string"}, "description": "í•´ë‹¹ ë‹¨ê³„ì˜ íƒœìŠ¤í¬ IDë“¤"},
                            "notes": {"type": "string", "description": "ë‹¨ê³„ë³„ ì°¸ê³ ì‚¬í•­"}
                        }
                    }
                },
                "risks_global": {"type": "array", "items": {"type": "string"}, "description": "ì „ì²´ í”„ë¡œì íŠ¸ ë¦¬ìŠ¤í¬"},
                "mitigations_global": {"type": "array", "items": {"type": "string"}, "description": "ì „ì²´ í”„ë¡œì íŠ¸ ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ"}
            }
        }

        # LangChainì´ ì´í•´í•  ìˆ˜ ìžˆëŠ” í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ ë³€í™˜
        user_task = self.input_value.content if hasattr(self.input_value, 'content') else str(self.input_value)
        self.user_task = user_task  # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ìž¥
        
        # LLMì´ ìžˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
        if not hasattr(self, 'llm') or self.llm is None:
            msg = "LLMì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Language Model ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)

        # LLMì„ ì‚¬ìš©í•˜ì—¬ ìž‘ì—… ê³„íš ìˆ˜ë¦½
        chain = planning_prompt | self.llm | JsonOutputParser()
        
        try:
            
            # chat_historyë¥¼ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            langchain_chat_history = []
            if self.chat_history:
                for msg in self.chat_history:
                    if hasattr(msg, 'content') and hasattr(msg, 'type'):
                        if msg.type == "human":
                            langchain_chat_history.append(HumanMessage(content=msg.content))
                        elif msg.type == "ai":
                            langchain_chat_history.append(AIMessage(content=msg.content))
                        else:
                            langchain_chat_history.append(HumanMessage(content=str(msg.content)))

            result = await chain.ainvoke({
                "user_task": user_task,
                "available_agents": json.dumps(available_agents, ensure_ascii=False, indent=2),
                "output_schema": json.dumps(output_schema, ensure_ascii=False, indent=2),
                "chat_history": langchain_chat_history
            })
            
            logger.info(f"Work plan created with {len(result.get('work_breakdown', []))} tasks")

            # ìˆ˜ë¦½ëœ ìž‘ì—… ì œëª©ë“¤ ì¶œë ¥
            self._log_work_breakdown(result)
            
            return result
            
        except Exception as e:
            logger.error(f"Error creating work plan: {e}")
            raise

    def get_default_work_plan(self, user_task: str, available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """LLMì´ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ìž‘ì—… ê³„íš ìƒì„±"""
        logger.info("Generating default work plan")

        # ì‚¬ìš©ìž ìž…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìž‘ì—… ìœ í˜• ê²°ì •
        task_type = self.analyze_task_type(user_task)
        task_title = self.generate_task_title(user_task, task_type)
        
        # ê¸°ë³¸ ìž‘ì—… ê³„íš ìƒì„±
        work_plan = {
            "goal": f"ì‚¬ìš©ìž ìš”ì²­ ì²˜ë¦¬: {user_task}",
            "assumptions": [
                f"ì‚¬ìš©ìžê°€ {task_type} ìž‘ì—…ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.",
                "ë‚´ìž¥ ê¸°ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            ],
            "work_breakdown": [
                {
                    "id": "T1",
                    "title": task_title,
                    "agent": "self",
                    "skills": [task_type],
                    "inputs": [user_task],
                    "outputs": [f"{task_type} ê²°ê³¼"],
                    "dod": ["ìž‘ì—…ì´ ì™„ë£Œë¨"],
                    "est_hours": 0.1,
                    "dependencies": [],
                    "parallelizable": False,
                    "risk": ["ê¸°ë³¸ ì²˜ë¦¬"],
                    "mitigation": ["í‘œì¤€ ì ˆì°¨ ì‚¬ìš©"],
                    "bus": {
                        "use_bus": False,
                        "topics": [],
                        "role": "consumer",
                        "message_schema": {},
                        "qos": {},
                        "contracts": []
                    }
                }
            ],
            "critical_path": ["T1"],
            "execution_plan": [
                {
                    "phase": "Execution",
                    "targets": ["T1"],
                    "notes": f"{task_type} ìž‘ì—…ì„ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤."
                }
            ],
            "risks_global": ["ê¸°ë³¸ ì²˜ë¦¬ ì œí•œ"],
            "mitigations_global": ["í•„ìš”ì‹œ ìˆ˜ë™ ê°œìž…"]
        }

        logger.info(f"Default work plan created with {len(work_plan['work_breakdown'])} tasks")
        return work_plan

    def analyze_task_type(self, user_task: str) -> str:
        """ì‚¬ìš©ìž ìž…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìž‘ì—… ìœ í˜•ì„ ê²°ì •"""
        user_task_lower = user_task.lower()
        
        if any(keyword in user_task_lower for keyword in ["ë¶„ì„", "ë‹¨ì–´", "ë¬¸ìž", "ê°œìˆ˜", "í†µê³„"]):
            return "í…ìŠ¤íŠ¸ ë¶„ì„"
        elif any(keyword in user_task_lower for keyword in ["ì§ˆë¬¸", "ë‹µë³€", "ë¬¼ì–´", "ì•Œë ¤", "ì„¤ëª…", "?", "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ"]):
            return "ì§ˆì˜ì‘ë‹µ"
        elif any(keyword in user_task_lower for keyword in ["ìš”ì•½", "ì •ë¦¬", "ê°„ì¶”", "í•µì‹¬"]):
            return "ìš”ì•½"
        elif any(keyword in user_task_lower for keyword in ["ìƒì„±", "ë§Œë“¤", "ìž‘ì„±", "ì°½ìž‘", "ì“°ê¸°"]):
            return "ìƒì„±"
        elif any(keyword in user_task_lower for keyword in ["ë²ˆì—­", "translate"]):
            return "ë²ˆì—­"
        elif any(keyword in user_task_lower for keyword in ["ê³„ì‚°", "ìˆ˜í•™", "ê³±ì…ˆ", "ë‚˜ëˆ—ì…ˆ", "ë”í•˜ê¸°", "ë¹¼ê¸°"]):
            return "ê³„ì‚°"
        else:
            return "ì¼ë°˜ ìž‘ì—…"

    def generate_task_title(self, user_task: str, task_type: str) -> str:
        """ìž‘ì—… ìœ í˜•ì— ë”°ë¥¸ ì ì ˆí•œ ì œëª© ìƒì„±"""
        if task_type == "í…ìŠ¤íŠ¸ ë¶„ì„":
            return "í…ìŠ¤íŠ¸ ë¶„ì„ ë° í†µê³„ ì¶”ì¶œ"
        elif task_type == "ì§ˆì˜ì‘ë‹µ":
            return "ì§ˆë¬¸ ì‘ë‹µ ì²˜ë¦¬"
        elif task_type == "ìš”ì•½":
            return "í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"
        elif task_type == "ìƒì„±":
            return "ì½˜í…ì¸  ìƒì„±"
        elif task_type == "ë²ˆì—­":
            return "ì–¸ì–´ ë²ˆì—­"
        elif task_type == "ê³„ì‚°":
            return "ìˆ˜í•™ ê³„ì‚° ìˆ˜í–‰"
        else:
            return "ì¼ë°˜ ìž‘ì—… ì²˜ë¦¬"

    def _log_work_breakdown(self, work_plan: Dict[str, Any]) -> None:
        """ìž‘ì—… ê³„íšì˜ ìž‘ì—… ëª©ë¡ì„ ë¡œê·¸ë¡œ ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if "work_breakdown" in work_plan:
            tasks = work_plan["work_breakdown"]
            logger.info(f"ìˆ˜ë¦½ëœ ìž‘ì—… ëª©ë¡ ({len(tasks)}ê°œ):")
            for i, task in enumerate(tasks, 1):
                title = task.get("title", f"Task {task.get('id', 'Unknown')}")
                outputs = task.get("outputs", [])
                dod = task.get("dod", [])
                logger.info(f"  {i}. {title}\r\n     ì¶œë ¥: {', '.join(outputs)}\r\n     ì™„ë£Œ ê¸°ì¤€: {', '.join(dod)}")

    def format_planner_result(self, available_agents: List[Dict[str, Any]], work_plan: Dict[str, Any]) -> str:
        """í”Œëž˜ë„ˆ ê²°ê³¼ë¥¼ ì‚¬ìš©ìž ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        
        try:
            logger.info("Starting format_planner_result")
            
            # í—¤ë”
            result_text = "ðŸŽ¯ **A2A í”Œëž˜ë„ˆ ì‹¤í–‰ ê²°ê³¼**\n\n"
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡
            result_text += f"ðŸ¤– **ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸** ({len(available_agents)}ê°œ)\n"
            if available_agents:
                for i, agent in enumerate(available_agents, 1):
                    agent_id = agent.get("id", "Unknown")
                    agent_name = agent.get("name", agent_id)
                    agent_url = agent.get("url", agent.get("endpoint", "N/A"))
                    result_text += f"  {i}. **{agent_name}** (ID: {agent_id})\n"
                    result_text += f"     URL: {agent_url}\n"
            else:
                result_text += "  ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            
            result_text += "\n"
            
            # ìž‘ì—… ê³„íš
            result_text += "ðŸ“‹ **ìž‘ì—… ê³„íš**\n"
            result_text += f"â€¢ ëª©í‘œ: {work_plan.get('goal', 'N/A')}\n"
            
            # ê°€ì •ì‚¬í•­
            assumptions = work_plan.get('assumptions', [])
            if assumptions:
                result_text += f"â€¢ ê°€ì •ì‚¬í•­:\n"
                for assumption in assumptions:
                    result_text += f"  - {assumption}\n"
            
            # ìž‘ì—… ë¶„í•´
            tasks = work_plan.get("work_breakdown", [])
            result_text += f"â€¢ ì´ ìž‘ì—… ìˆ˜: {len(tasks)}ê°œ\n\n"
            
            result_text += "ðŸ“Š **ìž‘ì—…ë³„ ìƒì„¸ ê³„íš**\n\n"
            
            for i, task in enumerate(tasks, 1):
                task_id = task["id"]
                task_title = task["title"]
                task_agent = task["agent"]
                task_skills = task.get("skills", [])
                task_inputs = task.get("inputs", [])
                task_outputs = task.get("outputs", [])
                task_dod = task.get("dod", [])
                task_est_hours = task.get("est_hours", 0)
                task_dependencies = task.get("dependencies", [])
                task_parallelizable = task.get("parallelizable", False)
                
                result_text += f"**{i}. {task_title}** (ID: {task_id})\n"
                result_text += f"   â€¢ ë‹´ë‹¹ ì—ì´ì „íŠ¸: {task_agent}\n"
                result_text += f"   â€¢ í•„ìš” ìŠ¤í‚¬: {', '.join(task_skills) if task_skills else 'N/A'}\n"
                result_text += f"   â€¢ ìž…ë ¥: {', '.join(task_inputs) if task_inputs else 'N/A'}\n"
                result_text += f"   â€¢ ì¶œë ¥: {', '.join(task_outputs) if task_outputs else 'N/A'}\n"
                result_text += f"   â€¢ ì™„ë£Œ ê¸°ì¤€: {', '.join(task_dod) if task_dod else 'N/A'}\n"
                result_text += f"   â€¢ ì¶”ì • ì‹œê°„: {task_est_hours}ì‹œê°„\n"
                result_text += f"   â€¢ ì˜ì¡´ì„±: {', '.join(task_dependencies) if task_dependencies else 'ì—†ìŒ'}\n"
                result_text += f"   â€¢ ë³‘ë ¬ ì‹¤í–‰: {'ê°€ëŠ¥' if task_parallelizable else 'ë¶ˆê°€ëŠ¥'}\n"
                result_text += "\n"
            
            # ì‹¤í–‰ ê³„íš
            execution_plan = work_plan.get("execution_plan", [])
            if execution_plan:
                result_text += "ðŸš€ **ì‹¤í–‰ ê³„íš**\n"
                for i, phase in enumerate(execution_plan, 1):
                    phase_name = phase.get("phase", f"Phase {i}")
                    phase_targets = phase.get("targets", [])
                    phase_notes = phase.get("notes", "")
                    result_text += f"  {i}. **{phase_name}**: {', '.join(phase_targets)}\n"
                    if phase_notes:
                        result_text += f"     ì°¸ê³ ì‚¬í•­: {phase_notes}\n"
                result_text += "\n"
            
            # ë¦¬ìŠ¤í¬ ë° ì™„í™” ë°©ì•ˆ
            risks_global = work_plan.get("risks_global", [])
            mitigations_global = work_plan.get("mitigations_global", [])
            
            if risks_global or mitigations_global:
                result_text += "âš ï¸ **ë¦¬ìŠ¤í¬ ë° ì™„í™” ë°©ì•ˆ**\n"
                if risks_global:
                    result_text += "â€¢ ë¦¬ìŠ¤í¬:\n"
                    for risk in risks_global:
                        result_text += f"  - {risk}\n"
                if mitigations_global:
                    result_text += "â€¢ ì™„í™” ë°©ì•ˆ:\n"
                    for mitigation in mitigations_global:
                        result_text += f"  - {mitigation}\n"
                result_text += "\n"
            
            # ì‚¬ìš©ìž ìš”ì²­ ì›ë¬¸ë„ í¬í•¨
            if hasattr(self, 'user_task') and self.user_task:
                result_text += f"ðŸ“ **ì›ë³¸ ìš”ì²­**: {self.user_task}\n"
            
            logger.info(f"format_planner_result completed, length: {len(result_text)}")
            return result_text
            
        except Exception as e:
            logger.error(f"Error in format_planner_result: {e}")
            return f"A2A í”Œëž˜ë„ˆ ì‹¤í–‰ ì™„ë£Œ!\n\nì—ì´ì „íŠ¸ ìˆ˜: {len(available_agents)}ê°œ\nìž‘ì—… ìˆ˜: {len(work_plan.get('work_breakdown', []))}ê°œ\n\nìƒì„¸ ê²°ê³¼ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."

    async def get_memory_data(self):
        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.
        messages = (
            await MemoryComponent(**self.get_base_args())
            .set(session_id=self.graph.session_id, order="Ascending", n_messages=self.n_messages)
            .retrieve_messages()
        )
        return [
            message for message in messages if getattr(message, "id", None) != getattr(self.input_value, "id", None)
        ]

    def get_llm(self):
        if not isinstance(self.agent_llm, str):
            return self.agent_llm, None

        try:
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if not provider_info:
                msg = f"Invalid model provider: {self.agent_llm}"
                raise ValueError(msg)

            component_class = provider_info.get("component_class")
            display_name = component_class.display_name
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix", "")

            return self._build_llm_model(component_class, inputs, prefix), display_name

        except Exception as e:
            logger.error(f"Error building {self.agent_llm} language model: {e!s}")
            msg = f"Failed to initialize language model: {e!s}"
            raise ValueError(msg) from e

    def _build_llm_model(self, component, inputs, prefix=""):
        model_kwargs = {}
        for input_ in inputs:
            if hasattr(self, f"{prefix}{input_.name}"):
                model_kwargs[input_.name] = getattr(self, f"{prefix}{input_.name}")
        return component.set(**model_kwargs).build_model()

    def set_component_params(self, component):
        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
        if provider_info:
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix")
            model_kwargs = {input_.name: getattr(self, f"{prefix}{input_.name}") for input_ in inputs}

            return component.set(**model_kwargs)
        return component

    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:
        """Delete specified fields from build_config."""
        for field in fields:
            build_config.pop(field, None)

    def update_input_types(self, build_config: dotdict) -> dotdict:
        """Update input types for all fields in build_config."""
        for key, value in build_config.items():
            if isinstance(value, dict):
                if value.get("input_types") is None:
                    build_config[key]["input_types"] = []
                # agent_llmì˜ input_typesë¥¼ LanguageModelìœ¼ë¡œ ê°•ì œ ì„¤ì •
                if key == "agent_llm":
                    build_config[key]["input_types"] = ["LanguageModel"]
            elif hasattr(value, "input_types") and value.input_types is None:
                value.input_types = []
                # agent_llmì˜ input_typesë¥¼ LanguageModelìœ¼ë¡œ ê°•ì œ ì„¤ì •
                if key == "agent_llm":
                    value.input_types = ["LanguageModel"]
        return build_config

    async def update_build_config(
        self, build_config: dotdict, field_value: str, field_name: str | None = None
    ) -> dotdict:
        # Iterate over all providers in the MODEL_PROVIDERS_DICT
        # Existing logic for updating build_config
        if field_name in ("agent_llm",):
            build_config["agent_llm"]["value"] = field_value
            provider_info = MODEL_PROVIDERS_DICT.get(field_value)
            if provider_info:
                component_class = provider_info.get("component_class")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call the component class's update_build_config method
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )

            provider_configs: dict[str, tuple[dict, list[dict]]] = {
                provider: (
                    MODEL_PROVIDERS_DICT[provider]["fields"],
                    [
                        MODEL_PROVIDERS_DICT[other_provider]["fields"]
                        for other_provider in MODEL_PROVIDERS_DICT
                        if other_provider != provider
                    ],
                )
                for provider in MODEL_PROVIDERS_DICT
            }
            if field_value in provider_configs:
                fields_to_add, fields_to_delete = provider_configs[field_value]

                # Delete fields from other providers
                for fields in fields_to_delete:
                    self.delete_fields(build_config, fields)

                # Add provider-specific fields
                if field_value == "OpenAI" and not any(field in build_config for field in fields_to_add):
                    build_config.update(fields_to_add)
                else:
                    build_config.update(fields_to_add)
                # Reset input types for agent_llm
                build_config["agent_llm"]["input_types"] = ["LanguageModel"]
            elif field_value == "Custom":
                # Delete all provider fields
                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)
                # Update with custom component
                custom_component = DropdownInput(
                    name="agent_llm",
                    display_name="Language Model",
                    options=[*sorted(MODEL_PROVIDERS), "Custom"],
                    value="Custom",
                    real_time_refresh=True,
                    input_types=["LanguageModel"],
                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]
                    + [{"icon": "brain"}],
                )
                build_config.update({"agent_llm": custom_component.to_dict()})
            # Update input types for all fields
            build_config = self.update_input_types(build_config)

            # Validate required keys
            default_keys = [
                "code",
                "_type",
                "agent_llm",
                "tools",
                "input_value",
                "add_current_date_tool",
                "system_prompt",
                "agent_description",
                "handle_parsing_errors",
                "verbose",
            ]
            
            # ëˆ„ë½ëœ í•„ìˆ˜ í‚¤ë“¤ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if "tools" not in build_config:
                build_config["tools"] = {"value": "", "input_types": ["Tool"]}
            if "input_value" not in build_config:
                build_config["input_value"] = {"value": "", "input_types": ["Message"]}
            if "agent_description" not in build_config:
                build_config["agent_description"] = {"value": "A helpful assistant with access to the following tools:"}
            if "system_prompt" not in build_config:
                build_config["system_prompt"] = {"value": None, "input_types": ["Message"]}
            
            missing_keys = [key for key in default_keys if key not in build_config]
            if missing_keys:
                msg = f"Missing required keys in build_config: {missing_keys}"
                raise ValueError(msg)
        if (
            isinstance(self.agent_llm, str)
            and self.agent_llm in MODEL_PROVIDERS_DICT
            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS
        ):
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if provider_info:
                component_class = provider_info.get("component_class")
                component_class = self.set_component_params(component_class)
                prefix = provider_info.get("prefix")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call each component class's update_build_config method
                    # remove the prefix from the field_name
                    if isinstance(field_name, str) and isinstance(prefix, str):
                        field_name = field_name.replace(prefix, "")
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )
        return dotdict({k: v.to_dict() if hasattr(v, "to_dict") else v for k, v in build_config.items()})

    async def _get_tools(self) -> list[Tool]:
        component_toolkit = _get_component_toolkit()
        tools_names = self._build_tools_names()
        agent_description = self.get_tool_description()
        # TODO: Agent Description Depreciated Feature to be removed
        description = f"{agent_description}{tools_names}"
        tools = component_toolkit(component=self).get_tools(
            tool_name="Call_Agent", tool_description=description, callbacks=self.get_langchain_callbacks()
        )
        if hasattr(self, "tools_metadata"):
            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)
        return tools
