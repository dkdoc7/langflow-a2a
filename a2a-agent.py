import json
import asyncio
from typing import List, Dict, Any, Optional
import aiohttp
from uuid import uuid4
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import JsonOutputParser


from langflow.base.agents.agent import LCToolsAgentComponent
from langflow.base.models.model_input_constants import (
    ALL_PROVIDER_FIELDS,
    MODEL_DYNAMIC_UPDATE_FIELDS,
    MODEL_PROVIDERS,
    MODEL_PROVIDERS_DICT,
    MODELS_METADATA,
)
from langflow.components.helpers.memory import MemoryComponent
from langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent

from langflow.custom.utils import update_component_build_config
from langflow.field_typing import Tool
from langflow.io import BoolInput, DropdownInput, HandleInput, IntInput, MultilineInput, Output, StrInput
from langflow.logging import logger
from langflow.schema.dotdict import dotdict
from langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI
from langflow.schema.message import Message


def create_prompt_from_component(prompt_component, default_system_message: str = "") -> ChatPromptTemplate:
    """
    í”„ë¡¬í”„íŠ¸ ì»´í¬ë„ŒíŠ¸ì—ì„œ ChatPromptTemplateì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        prompt_component: Langflow Prompt Componentì—ì„œ ì¶œë ¥ëœ Message ê°ì²´
        default_system_message: ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€
    
    Returns:
        ChatPromptTemplate: LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    """
    if not prompt_component:
        logger.warning("prompt_component is None or empty")
        return None
        
    try:
        # Message ê°ì²´ì—ì„œ template ì¶”ì¶œ
        if hasattr(prompt_component, 'template'):
            template_content = prompt_component.template
        elif hasattr(prompt_component, 'text'):
            template_content = prompt_component.text
        else:
            logger.warning("Prompt component format not recognized")
            return None
        
        # ChatPromptTemplate ìƒì„± (ë³€ìˆ˜ëŠ” ëŸ°íƒ€ì„ì— ì£¼ì…)
        # chat_history ë³€ìˆ˜ê°€ í¬í•¨ëœ ê²½ìš° MessagesPlaceholder ì¶”ê°€
        if "{chat_history}" in template_content:
            if default_system_message:
                return ChatPromptTemplate.from_messages([
                    ("system", default_system_message),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("human", template_content)
                ])
            else:
                return ChatPromptTemplate.from_messages([
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("human", template_content)
                ])
        else:
            if default_system_message:
                return ChatPromptTemplate.from_messages([
                    ("system", default_system_message),
                    ("human", template_content)
                ])
            else:
                return ChatPromptTemplate.from_messages([
                    ("human", template_content)
                ])
            
    except Exception as e:
        logger.error(f"Error creating prompt from component: {e}")
        return None



MODEL_PROVIDERS_LIST = ["Anthropic", "Google Generative AI", "Groq", "OpenAI"]


class A2AAgentComponent(ToolCallingAgentComponent):
    display_name: str = "A2A Agent"
    description: str = "A2A Discovery ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ì—¬ ë©€í‹° ì—ì´ì „íŠ¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸"
    documentation: str = "https://docs.langflow.org/agents"
    icon = "bot"
    beta = False
    name = "A2A Agent"



    inputs = [
        # LLM ì—°ê²°ì„ ìœ„í•œ ì…ë ¥ í•„ë“œ
        DropdownInput(
            name="agent_llm",
            display_name="Model Provider",
            info="The provider of the language model that the agent will use to generate responses.",
            options=[*MODEL_PROVIDERS_LIST, "Custom"],
            value="OpenAI",
            real_time_refresh=True,
            input_types=["LanguageModel"],
            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST] + [{"icon": "brain"}],
        ),
        # OpenAI ëª¨ë¸ ì„¤ì • ì…ë ¥ë“¤
        *MODEL_PROVIDERS_DICT["OpenAI"]["inputs"],

        StrInput(
            name="a2a_api_base",
            display_name="A2A API Base URL",
            info="A2A Discovery ì„œë¹„ìŠ¤ì˜ API ê¸°ë³¸ URL (ì˜ˆ: http://localhost:8000, https://api.example.com)",
            value="http://localhost:8000",
            advanced=False,
        ),
        MultilineInput(
            name="system_prompt",
            display_name="Agent Instructions",
            info="System Prompt: A2A ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° ì§€ì‹œì‚¬í•­ê³¼ ì»¨í…ìŠ¤íŠ¸",
            value="""ë‹¹ì‹ ì€ A2A Discovery ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ì—¬ ë©€í‹° ì—ì´ì „íŠ¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” A2A ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
1. A2A Discovery ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ì¡°íšŒ
2. ì‚¬ìš©ì ì‘ì—…ì„ ë¶„ì„í•˜ê³  ì‘ì—… ë¶„í•  ê³„íš ìˆ˜ë¦½
3. ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—… ìœ„ì„ ë° ì‹¤í–‰
4. ê²°ê³¼ ë¶„ì„ ë° ê°œì„ ì•ˆ ì œì‹œ (Planning-Dispatcher-Critic íŒ¨í„´)

ì‘ì—… ê³„íš ìˆ˜ë¦½ ì‹œ ë‹¤ìŒ ì›ì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
- ëª©í‘œë¥¼ ëª…í™•í•œ ì‚°ì¶œë¬¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„í•´ (30-90ë¶„ ë‚´ ì™„ë£Œ ê°€ëŠ¥í•œ í¬ê¸°)
- ê° íƒœìŠ¤í¬ì— ë‹´ë‹¹ ì—ì´ì „íŠ¸/í•„ìš” ìŠ¤í‚¬/ì…ì¶œë ¥/ì™„ë£Œ ê¸°ì¤€/ì˜ì¡´ì„±/ì¶”ì • ì‹œê°„ ëª…ì‹œ
- ìœ„ìƒì •ë ¬ ê°€ëŠ¥í•œ ìˆœì„œì˜ ì‹¤í–‰ ê³„íš ì œì‹œ
- ë¦¬ìŠ¤í¬ì™€ ëŒ€ì•ˆ í¬í•¨, ë³‘ë ¬í™” ê°€ëŠ¥ êµ¬ê°„ ëª…ì‹œ
- OUTPUT_SCHEMA í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ""",
            advanced=False,
        ),
        IntInput(
            name="n_messages",
            display_name="Number of Chat History Messages",
            value=100,
            info="Number of chat history messages to retrieve.",
            advanced=True,
            show=True,
        ),
        # ChatInput ì—°ê²°ì„ ìœ„í•œ ì…ë ¥ í•„ë“œ
        StrInput(
            name="input_value",
            display_name="Input Value",
            info="ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ ë˜ëŠ” ChatInputì—ì„œ ì—°ê²°ëœ ê°’",
            value="",
            advanced=False,
            input_types=["Message"],
        ),
        # Tools ì—°ê²°ì„ ìœ„í•œ ì…ë ¥ í•„ë“œ
        StrInput(
            name="tools",
            display_name="Tools",
            info="ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬ë“¤",
            value="",   
            advanced=True,
        ),
        # Agent Description ì…ë ¥ í•„ë“œ
        StrInput(
            name="agent_description",
            display_name="Agent Description",
            info="ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì„¤ëª…",
            value="A helpful assistant with access to the following tools:",
            advanced=True,
        ),
        # ê¸°ë³¸ ì—ì´ì „íŠ¸ ì…ë ¥ë“¤ (max_iterations ì œì™¸)
        BoolInput(
            name="handle_parsing_errors",
            display_name="Handle Parsing Errors",
            value=True,
            info="Whether to handle parsing errors.",
            advanced=True,
        ),
        BoolInput(
            name="verbose",
            display_name="Verbose",
            value=False,
            info="Whether to run in verbose mode.",
            advanced=True,
        ),
        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ max_iterationsë¥¼ ë¬´ì‹œí•˜ê³  A2A ì „ìš© ì‚¬ìš©
        IntInput(
            name="a2a_max_iterations",
            display_name="A2A Maximum Iterations",
            value=3,
            info="Planning-Dispatcher-Critic ì‚¬ì´í´ì˜ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3íšŒ)",
            advanced=True,
        ),
        BoolInput(
            name="add_current_date_tool",
            display_name="Current Date",
            advanced=True,
            info="If true, will add a tool to the agent that returns the current date.",
            value=True,
        ),
        BoolInput(
            name="enable_event_bus",
            display_name="Enable Event Bus",
            advanced=True,
            info="ì´ë²¤íŠ¸ ë²„ìŠ¤ ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ì—¬ íƒœìŠ¤í¬ ê°„ ìƒí˜¸ì‘ì—…ì„ ê´€ë¦¬",
            value=False,
        ),
        # Prompt Component ì…ë ¥ í•„ë“œë“¤ (í•„ìˆ˜)
        HandleInput(
            name="work_plan_prompt",
            display_name="Work Plan Prompt (í•„ìˆ˜)",
            info="ì‘ì—… ê³„íš ìˆ˜ë¦½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (Prompt Template ì»´í¬ë„ŒíŠ¸ ì—°ê²° í•„ìˆ˜)",
            advanced=False,
            input_types=["Message"],
            required=True,
        ),
        HandleInput(
            name="planning_prompt", 
            display_name="Planning Prompt (í•„ìˆ˜)",
            info="ê³„íš ê²€í†  ë° ê°œì„ ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (Prompt Template ì»´í¬ë„ŒíŠ¸ ì—°ê²° í•„ìˆ˜)",
            advanced=False,
            input_types=["Message"],
            required=True,
        ),

        HandleInput(
            name="critic_prompt",
            display_name="Critic Prompt (í•„ìˆ˜)", 
            info="ì‹¤í–‰ ê²°ê³¼ ë¶„ì„ ë° ë¹„í‰ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (Prompt Template ì»´í¬ë„ŒíŠ¸ ì—°ê²° í•„ìˆ˜)",
            advanced=False,
            input_types=["Message"],
            required=True,
        ),

    ]
    outputs = [
        Output(name="response", display_name="Response", method="message_response")
    ]

    async def message_response(self) -> Message:
        """A2A Agentì˜ ë©”ì¸ ì‘ë‹µ ë©”ì„œë“œ"""
        logger.info("message_response called - starting A2A Agent execution")

        try:
            # LLM ì´ˆê¸°í™”
            await self._initialize_llm()
            
            # ì‹¤ì œ A2A Agent ë¡œì§ ì‹¤í–‰
            result = await self.run_a2a_agent()
            return result
        except Exception as e:
            logger.error(f"A2A Agent execution error: {e}")
            return Message(
                text=f"A2A Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )
    


    async def _initialize_llm(self):
        """LLM ë° í•„ìˆ˜ ì†ì„± ì´ˆê¸°í™”"""
        try:
            # chat_history ì´ˆê¸°í™”
            if not hasattr(self, 'chat_history'):
                self.chat_history = []
                logger.info("Initialized empty chat_history")
            
            if hasattr(self, 'llm') and self.llm is not None:
                logger.info("LLM already initialized")
                return
                
            # agent_llmì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(self, 'agent_llm') and self.agent_llm is not None:
                logger.info(f"Initializing LLM with agent_llm: {type(self.agent_llm)}")
                self.llm = self.agent_llm
            else:
                logger.warning("No agent_llm provided, LLM will not be available")
                self.llm = None
                
        except Exception as e:
            logger.error(f"Failed to initialize LLM: {e}")
            self.llm = None

    async def run_a2a_agent(self) -> Message:
        """A2A ì—ì´ì „íŠ¸ì˜ ë©”ì¸ ì‹¤í–‰ ë¡œì§"""
        try:
            # 1. A2A Discovery ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ
            available_agents = await self.get_available_agents()
            logger.info(f"Available agents: {len(available_agents)} agents found")

            # 2. ì‘ì—… ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½
            work_plan = await self.create_work_plan(available_agents)
            logger.info(f"Work plan created with {len(work_plan.get('work_breakdown', []))} tasks")

            # 3. Planning-Dispatcher-Critic ì‚¬ì´í´ ì‹¤í–‰
            final_result = await self.execute_planning_dispatcher_critic_cycle(work_plan, available_agents)
            logger.info(f"Final result: {final_result}")

            # 4. ìµœì¢… ê²°ê³¼ ì •ë¦¬ ë° ë°˜í™˜
            user_friendly_result = self.format_final_result(work_plan, final_result)
            logger.info(f"Formatted result length: {len(user_friendly_result)}")
            logger.info(f"First 100 chars: {user_friendly_result[:100]}")
            
            # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ë°±ì—… ë©”ì‹œì§€ ì œê³µ
            if not user_friendly_result or len(user_friendly_result.strip()) == 0:
                user_friendly_result = f"A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ!\n\nì‘ì—… ê²°ê³¼:\n{json.dumps(final_result, ensure_ascii=False, indent=2)}"
                logger.warning("Empty result detected, using backup message")
            
            return Message(
                text=user_friendly_result,
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )

        except Exception as e:
            logger.error(f"Error in A2A agent execution: {e}")
            return Message(
                text=f"A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI
            )

    def get_default_work_plan(self, user_task: str, available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """LLMì´ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ì‘ì—… ê³„íš ìƒì„±"""
        logger.info("Generating default work plan")

        # ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì‘ì—… ìœ í˜• ê²°ì •
        task_type = self.analyze_task_type(user_task)
        task_title = self.generate_task_title(user_task, task_type)
        
        # ê¸°ë³¸ ì‘ì—… ê³„íš ìƒì„±
        work_plan = {
            "goal": f"ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬: {user_task}",
            "assumptions": [
                f"ì‚¬ìš©ìê°€ {task_type} ì‘ì—…ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.",
                "ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            ],
            "work_breakdown": [
                {
                    "id": "T1",
                    "title": task_title,
                    "agent": "self",
                    "skills": [task_type],
                    "inputs": [user_task],
                    "outputs": [f"{task_type} ê²°ê³¼"],
                    "dod": ["ì‘ì—…ì´ ì™„ë£Œë¨"],
                    "est_hours": 0.1,
                    "dependencies": [],
                    "parallelizable": False,
                    "risk": ["ê¸°ë³¸ ì²˜ë¦¬"],
                    "mitigation": ["í‘œì¤€ ì ˆì°¨ ì‚¬ìš©"],
                    "bus": {
                        "use_bus": False,
                        "topics": [],
                        "role": "consumer",
                        "message_schema": {},
                        "qos": {},
                        "contracts": []
                    }
                }
            ],
            "critical_path": ["T1"],
            "execution_plan": [
                {
                    "phase": "Execution",
                    "targets": ["T1"],
                    "notes": f"{task_type} ì‘ì—…ì„ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤."
                }
            ],
            "risks_global": ["ê¸°ë³¸ ì²˜ë¦¬ ì œí•œ"],
            "mitigations_global": ["í•„ìš”ì‹œ ìˆ˜ë™ ê°œì…"]
        }

        logger.info(f"Default work plan created with {len(work_plan['work_breakdown'])} tasks")
        return work_plan

    def analyze_task_type(self, user_task: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì‘ì—… ìœ í˜•ì„ ê²°ì •"""
        user_task_lower = user_task.lower()
        
        if any(keyword in user_task_lower for keyword in ["ë¶„ì„", "ë‹¨ì–´", "ë¬¸ì", "ê°œìˆ˜", "í†µê³„"]):
            return "í…ìŠ¤íŠ¸ ë¶„ì„"
        elif any(keyword in user_task_lower for keyword in ["ì§ˆë¬¸", "ë‹µë³€", "ë¬¼ì–´", "ì•Œë ¤", "ì„¤ëª…", "?", "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ"]):
            return "ì§ˆì˜ì‘ë‹µ"
        elif any(keyword in user_task_lower for keyword in ["ìš”ì•½", "ì •ë¦¬", "ê°„ì¶”", "í•µì‹¬"]):
            return "ìš”ì•½"
        elif any(keyword in user_task_lower for keyword in ["ìƒì„±", "ë§Œë“¤", "ì‘ì„±", "ì°½ì‘", "ì“°ê¸°"]):
            return "ìƒì„±"
        elif any(keyword in user_task_lower for keyword in ["ë²ˆì—­", "translate"]):
            return "ë²ˆì—­"
        elif any(keyword in user_task_lower for keyword in ["ê³„ì‚°", "ìˆ˜í•™", "ê³±ì…ˆ", "ë‚˜ëˆ—ì…ˆ", "ë”í•˜ê¸°", "ë¹¼ê¸°"]):
            return "ê³„ì‚°"
        else:
            return "ì¼ë°˜ ì‘ì—…"

    def generate_task_title(self, user_task: str, task_type: str) -> str:
        """ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ì ì ˆí•œ ì œëª© ìƒì„±"""
        if task_type == "í…ìŠ¤íŠ¸ ë¶„ì„":
            return "í…ìŠ¤íŠ¸ ë¶„ì„ ë° í†µê³„ ì¶”ì¶œ"
        elif task_type == "ì§ˆì˜ì‘ë‹µ":
            return "ì§ˆë¬¸ ì‘ë‹µ ì²˜ë¦¬"
        elif task_type == "ìš”ì•½":
            return "í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"
        elif task_type == "ìƒì„±":
            return "ì½˜í…ì¸  ìƒì„±"
        elif task_type == "ë²ˆì—­":
            return "ì–¸ì–´ ë²ˆì—­"
        elif task_type == "ê³„ì‚°":
            return "ìˆ˜í•™ ê³„ì‚° ìˆ˜í–‰"
        else:
            return "ì¼ë°˜ ì‘ì—… ì²˜ë¦¬"

    def format_final_result(self, work_plan: Dict[str, Any], final_result: Dict[str, Any]) -> str:
        """ìµœì¢… ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        
        try:
            logger.info("Starting format_final_result")
            logger.info(f"work_plan keys: {list(work_plan.keys()) if work_plan else 'None'}")
            logger.info(f"final_result keys: {list(final_result.keys()) if final_result else 'None'}")
            
            # í—¤ë”
            result_text = "ğŸ¯ **A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼**\n\n"
            
            # ì‘ì—… ê°œìš”
            tasks = work_plan.get("work_breakdown", [])
            execution_results = final_result.get("execution_results", {})
            iterations = final_result.get("iterations", 0)
            
            result_text += f"ğŸ“‹ **ì‘ì—… ê°œìš”**\n"
            result_text += f"â€¢ ì´ ì‘ì—… ìˆ˜: {len(tasks)}ê°œ\n"
            result_text += f"â€¢ ì™„ë£Œëœ ì‘ì—…: {len(execution_results)}ê°œ\n"
            result_text += f"â€¢ ì‹¤í–‰ ë°˜ë³µ: {iterations + 1}íšŒ\n\n"
            
            # ê° ì‘ì—…ë³„ ê²°ê³¼
            result_text += "ğŸ“Š **ì‘ì—…ë³„ ì‹¤í–‰ ê²°ê³¼**\n\n"
            
            for i, task in enumerate(tasks, 1):
                task_id = task["id"]
                task_title = task["title"]
                task_agent = task["agent"]
                
                result_text += f"**{i}. {task_title}**\n"
                result_text += f"   â€¢ ë‹´ë‹¹: {task_agent}\n"
                
                if task_id in execution_results:
                    task_result = execution_results[task_id]
                    status = task_result.get("status", "unknown")
                    
                    if status == "completed":
                        result_text += f"   â€¢ ìƒíƒœ: âœ… ì™„ë£Œ\n"
                        
                        # ê²°ê³¼ ë‚´ìš© ì¶”ì¶œ
                        result_data = task_result.get("result", {})
                        
                        # ìƒˆë¡œìš´ ì§ì ‘ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
                        if isinstance(result_data, dict):
                            if "execution_method" in result_data:
                                execution_method = result_data["execution_method"]
                                result_content = result_data.get("result", "")
                                
                                if execution_method == "text_analysis":
                                    # í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼
                                    analysis = result_data.get("analysis", {})
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„\n"
                                    result_text += f"   â€¢ ë‹¨ì–´ ìˆ˜: {analysis.get('ë‹¨ì–´_ìˆ˜', 'N/A')}ê°œ\n"
                                    result_text += f"   â€¢ ë¬¸ì ìˆ˜: {analysis.get('ë¬¸ì_ìˆ˜_ê³µë°±í¬í•¨', 'N/A')}ê°œ\n"
                                    result_text += f"   â€¢ ë¬¸ì¥ ìˆ˜: {analysis.get('ë¬¸ì¥_ìˆ˜', 'N/A')}ê°œ\n"
                                elif execution_method in ["llm_qa", "default_qa"]:
                                    # ì§ˆì˜ì‘ë‹µ ê²°ê³¼
                                    question = result_data.get("question", "")
                                    answer = result_data.get("answer", "")
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: â“ ì§ˆì˜ì‘ë‹µ\n"
                                    result_text += f"   â€¢ ì§ˆë¬¸: {question[:50]}{'...' if len(question) > 50 else ''}\n"
                                    result_text += f"   â€¢ ë‹µë³€: {answer[:100]}{'...' if len(answer) > 100 else ''}\n"
                                elif execution_method in ["llm_summary", "basic_summary"]:
                                    # ìš”ì•½ ê²°ê³¼
                                    original_length = len(result_data.get("original_text", ""))
                                    summary = result_data.get("summary", "")
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: ğŸ“ ìš”ì•½\n"
                                    result_text += f"   â€¢ ì›ë³¸ ê¸¸ì´: {original_length}ì\n"
                                    result_text += f"   â€¢ ìš”ì•½: {summary[:100]}{'...' if len(summary) > 100 else ''}\n"
                                elif execution_method in ["llm_generation", "default_generation"]:
                                    # ìƒì„± ê²°ê³¼
                                    request = result_data.get("request", "")
                                    generated = result_data.get("generated_content", "")
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: âœ¨ ìƒì„±\n"
                                    result_text += f"   â€¢ ìš”ì²­: {request[:50]}{'...' if len(request) > 50 else ''}\n"
                                    result_text += f"   â€¢ ìƒì„± ê²°ê³¼: {generated[:100]}{'...' if len(generated) > 100 else ''}\n"
                                elif execution_method in ["llm_general", "basic_general"]:
                                    # ì¼ë°˜ ì‘ì—… ê²°ê³¼
                                    task_desc = result_data.get("task_description", "")
                                    user_inp = result_data.get("user_input", "")
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: ğŸ”§ ì¼ë°˜ ì‘ì—…\n"
                                    result_text += f"   â€¢ ì‘ì—…: {task_desc}\n"
                                    result_text += f"   â€¢ ì…ë ¥: {user_inp[:50]}{'...' if len(user_inp) > 50 else ''}\n"
                                elif execution_method == "direct_calculation":
                                    # ì§ì ‘ ê³„ì‚° ê²°ê³¼
                                    calc_result = result_data.get("result", "")
                                    inputs = result_data.get("inputs", {})
                                    calculation = result_data.get("calculation", {})
                                    
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: ğŸ§® ìˆ˜í•™ ê³„ì‚°\n"
                                    result_text += f"   â€¢ ê²°ê³¼: {calc_result}\n"
                                    if inputs:
                                        result_text += f"   â€¢ ì…ë ¥ê°’: ë‹¨ì–´ìˆ˜ {inputs.get('word_count', 'N/A')}, í† í°ìˆ˜ {inputs.get('token_count', 'N/A')}\n"
                                else:
                                    # ê¸°íƒ€ ì§ì ‘ ì‹¤í–‰ ê²°ê³¼
                                    result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: {execution_method}\n"
                                    if isinstance(result_content, str):
                                        lines = result_content.strip().split('\n')
                                        result_text += f"   â€¢ ê²°ê³¼:\n"
                                        for line in lines[:3]:  # ì²« 3ì¤„ë§Œ í‘œì‹œ
                                            result_text += f"     {line.strip()}\n"
                                        if len(lines) > 3:
                                            result_text += "     ...\n"
                                            
                            elif "agent_response" in result_data:
                                # A2A ì—ì´ì „íŠ¸ ì‘ë‹µ (ê¸°ì¡´ ë¡œì§)
                                agent_response = result_data["agent_response"]
                                if isinstance(agent_response, dict) and "result" in agent_response:
                                    response_content = agent_response["result"]
                                    if isinstance(response_content, dict) and "parts" in response_content:
                                        for part in response_content["parts"]:
                                            if part.get("kind") == "text":
                                                text_content = part.get("text", "")
                                                # í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                                                lines = text_content.strip().split('\n')
                                                result_text += f"   â€¢ ì‹¤í–‰ ë°©ë²•: ğŸ¤– ì™¸ë¶€ ì—ì´ì „íŠ¸\n"
                                                result_text += f"   â€¢ ê²°ê³¼:\n"
                                                for line in lines[:3]:  # ì²« 3ì¤„ë§Œ í‘œì‹œ
                                                    result_text += f"     {line.strip()}\n"
                                                if len(lines) > 3:
                                                    result_text += "     ...\n"
                                                break
                        elif isinstance(result_data, str):
                            # ë‹¨ìˆœ ë¬¸ìì—´ ê²°ê³¼
                            lines = result_data.strip().split('\n')
                            result_text += f"   â€¢ ê²°ê³¼:\n"
                            for line in lines[:3]:  # ì²« 3ì¤„ë§Œ í‘œì‹œ
                                result_text += f"     {line.strip()}\n"
                            if len(lines) > 3:
                                result_text += "     ...\n"
                    elif status == "failed":
                        result_text += f"   â€¢ ìƒíƒœ: âŒ ì‹¤íŒ¨\n"
                        error = task_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        result_text += f"   â€¢ ì˜¤ë¥˜: {error}\n"
                    elif status == "skipped":
                        result_text += f"   â€¢ ìƒíƒœ: â­ï¸ ê±´ë„ˆëœ€\n"
                        reason = task_result.get("reason", "")
                        result_text += f"   â€¢ ì‚¬ìœ : {reason}\n"
                else:
                    result_text += f"   â€¢ ìƒíƒœ: â¸ï¸ ë¯¸ì‹¤í–‰\n"
                
                result_text += "\n"
            
            # ìµœì¢… ìš”ì•½
            completed_count = sum(1 for result in execution_results.values() if result.get("status") == "completed")
            failed_count = sum(1 for result in execution_results.values() if result.get("status") == "failed")
            
            result_text += "ğŸ **ìµœì¢… ìš”ì•½**\n"
            if completed_count == len(tasks) and failed_count == 0:
                result_text += "âœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
            elif failed_count > 0:
                result_text += f"âš ï¸ {failed_count}ê°œ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({completed_count}/{len(tasks)} ì™„ë£Œ)\n"
            else:
                result_text += f"ğŸ”„ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ({completed_count}/{len(tasks)} ì™„ë£Œ)\n"
            
            # ì‚¬ìš©ì ìš”ì²­ ì›ë¬¸ë„ í¬í•¨
            if hasattr(self, 'user_task') and self.user_task:
                result_text += f"\nğŸ“ **ì›ë³¸ ìš”ì²­**: {self.user_task}\n"
            
            logger.info(f"format_final_result completed, length: {len(result_text)}")
            return result_text
            
        except Exception as e:
            logger.error(f"Error in format_final_result: {e}")
            return f"A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ!\n\nì‘ì—… ì™„ë£Œ: {len(final_result.get('execution_results', {}))}ê°œ\nìƒíƒœ: {final_result.get('status', 'unknown')}\n\nìƒì„¸ ê²°ê³¼ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."

    async def get_available_agents(self) -> List[Dict[str, Any]]:
        """A2A Discovery ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ì¡°íšŒ"""
        try:
            api_url = f"{self.a2a_api_base}/agents?status=active"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(api_url) as response:
                    if response.status == 200:
                        response_data = await response.json()
                        logger.info(f"A2A Discovery response: {response_data}")
                        
                        # A2A Discovery ì„œë¹„ìŠ¤ëŠ” AgentListResponse í˜•íƒœë¡œ ì‘ë‹µ: {"agents": [...]}
                        if isinstance(response_data, dict) and 'agents' in response_data:
                            agents = response_data['agents']
                            logger.info(f"Successfully retrieved {len(agents)} agents from A2A Discovery service")
                            return agents
                        else:
                            logger.warning(f"Unexpected response format from A2A Discovery service: {type(response_data)}")
                            return []
                    else:
                        logger.warning(f"Failed to get agents from A2A Discovery service: {response.status}")
                        return []
        except Exception as e:
            logger.warning(f"Error connecting to A2A Discovery service: {e}")
            return []
        

    async def create_work_plan(self, available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì‘ì—…ì„ ë¶„ì„í•˜ê³  ì‘ì—… ë¶„í•  ê³„íšì„ ìˆ˜ë¦½"""
        
        # Work Plan Prompt í•„ìˆ˜ ì—°ê²° í™•ì¸
        if not hasattr(self, 'work_plan_prompt') or not self.work_plan_prompt:
            msg = "Work Plan Promptê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Prompt Template ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
                
        planning_prompt = create_prompt_from_component(
            self.work_plan_prompt,
            default_system_message=self.system_prompt
        )
        
        if planning_prompt is None:
            msg = "Work Plan Prompt ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)

        # OUTPUT_SCHEMA ì •ì˜
        output_schema = {
            "type": "object",
            "properties": {
                "goal": {"type": "string", "description": "ì „ì²´ ëª©í‘œ"},
                "assumptions": {"type": "array", "items": {"type": "string"}, "description": "ê°€ì •ì‚¬í•­ë“¤"},
                "work_breakdown": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string", "description": "íƒœìŠ¤í¬ ID (ì˜ˆ: T1, T2)"},
                            "title": {"type": "string", "description": "íƒœìŠ¤í¬ ì œëª©"},
                            "agent": {"type": "string", "description": "ë‹´ë‹¹ ì—ì´ì „íŠ¸ ID ë˜ëŠ” ì´ë¦„"},
                            "skills": {"type": "array", "items": {"type": "string"}, "description": "í•„ìš”í•œ ìŠ¤í‚¬ë“¤"},
                            "inputs": {"type": "array", "items": {"type": "string"}, "description": "ì…ë ¥ í•­ëª©ë“¤"},
                            "outputs": {"type": "array", "items": {"type": "string"}, "description": "ì¶œë ¥ í•­ëª©ë“¤"},
                            "dod": {"type": "array", "items": {"type": "string"}, "description": "ì™„ë£Œ ê¸°ì¤€(Definition of Done)"},
                            "est_hours": {"type": "number", "description": "ì¶”ì • ì†Œìš” ì‹œê°„(ì‹œê°„ ë‹¨ìœ„)"},
                            "dependencies": {"type": "array", "items": {"type": "string"}, "description": "ì˜ì¡´ì„± íƒœìŠ¤í¬ IDë“¤"},
                            "parallelizable": {"type": "boolean", "description": "ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€"},
                            "risk": {"type": "array", "items": {"type": "string"}, "description": "ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤"},
                            "mitigation": {"type": "array", "items": {"type": "string"}, "description": "ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆë“¤"},
                            "bus": {
                                "type": "object",
                                "properties": {
                                    "use_bus": {"type": "boolean"},
                                    "topics": {"type": "array", "items": {"type": "string"}},
                                    "role": {"type": "string", "enum": ["producer", "consumer", "both"]},
                                    "message_schema": {"type": "object"},
                                    "qos": {"type": "object"},
                                    "contracts": {"type": "array", "items": {"type": "string"}}
                                }
                            }
                        }
                    }
                },
                "critical_path": {"type": "array", "items": {"type": "string"}, "description": "í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤ íƒœìŠ¤í¬ IDë“¤"},
                "execution_plan": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "phase": {"type": "string", "description": "ì‹¤í–‰ ë‹¨ê³„"},
                            "targets": {"type": "array", "items": {"type": "string"}, "description": "í•´ë‹¹ ë‹¨ê³„ì˜ íƒœìŠ¤í¬ IDë“¤"},
                            "notes": {"type": "string", "description": "ë‹¨ê³„ë³„ ì°¸ê³ ì‚¬í•­"}
                        }
                    }
                },
                "risks_global": {"type": "array", "items": {"type": "string"}, "description": "ì „ì²´ í”„ë¡œì íŠ¸ ë¦¬ìŠ¤í¬"},
                "mitigations_global": {"type": "array", "items": {"type": "string"}, "description": "ì „ì²´ í”„ë¡œì íŠ¸ ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ"}
            }
        }

        # LangChainì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ ë³€í™˜
        user_task = self.input_value.content if hasattr(self.input_value, 'content') else str(self.input_value)
        self.user_task = user_task  # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        
        # LLMì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ê¸°ë³¸ ê³„íš ë°˜í™˜
        if not hasattr(self, 'llm') or self.llm is None:
            logger.warning("LLM not available, using default work plan")
            return self.get_default_work_plan(user_task, available_agents)

        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—… ê³„íš ìˆ˜ë¦½
        chain = planning_prompt | self.llm | JsonOutputParser()
        
        try:
            
            # chat_historyë¥¼ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            langchain_chat_history = []
            if self.chat_history:
                for msg in self.chat_history:
                    if hasattr(msg, 'content') and hasattr(msg, 'type'):
                        if msg.type == "human":
                            langchain_chat_history.append(HumanMessage(content=msg.content))
                        elif msg.type == "ai":
                            langchain_chat_history.append(AIMessage(content=msg.content))
                        else:
                            langchain_chat_history.append(HumanMessage(content=str(msg.content)))

            result = await chain.ainvoke({
                "user_task": user_task,
                "available_agents": json.dumps(available_agents, ensure_ascii=False, indent=2),
                "output_schema": json.dumps(output_schema, ensure_ascii=False, indent=2),
                "chat_history": langchain_chat_history
            })
            
            logger.info("Work plan created successfully")
            
            # ìˆ˜ë¦½ëœ ì‘ì—… ì œëª©ë“¤ ì¶œë ¥
            if "work_breakdown" in result:
                tasks = result["work_breakdown"]
                logger.info(f"ìˆ˜ë¦½ëœ ì‘ì—… ëª©ë¡ ({len(tasks)}ê°œ):")
                for i, task in enumerate(tasks, 1):
                    title = task.get("title", f"Task {task.get('id', 'Unknown')}")
                    outputs = task.get("outputs", [])
                    dod = task.get("dod", [])
                    logger.info(f"  {i}. {title}\r\n     ì¶œë ¥: {', '.join(outputs)}\r\n     ì™„ë£Œ ê¸°ì¤€: {', '.join(dod)}")
            
                # ë””ë²„ê¹…: ì „ì²´ ì‘ì—… êµ¬ì¡° ë¡œê·¸
                logger.info(f"ì „ì²´ ì‘ì—… êµ¬ì¡° ë””ë²„ê¹…:")
                for i, task in enumerate(tasks, 1):
                    logger.info(f"  Task {i} ìƒì„¸: {task}")
            
            return result
            
        except Exception as e:
            logger.error(f"Error creating work plan: {e}")
            raise

    async def execute_planning_dispatcher_critic_cycle(
        self, 
        work_plan: Dict[str, Any], 
        available_agents: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Planning-Dispatcher-Critic ì‚¬ì´í´ì„ ì‹¤í–‰í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰"""
        
        current_plan = work_plan
        iteration = 0
        execution_results = {}  # ì´ˆê¸°í™”
        
        # A2A ì „ìš© ë°˜ë³µ íšŸìˆ˜
        max_iter = self.a2a_max_iterations
        logger.info(f"Starting PDC cycle with A2A max_iterations: {max_iter}")
        
        while iteration < max_iter:
            logger.info(f"Starting iteration {iteration + 1} of {max_iter}")
            
            try:
                # 1. Planning: í˜„ì¬ ê³„íš ê²€í†  ë° ê°œì„ 
                proposed_improved_plan = await self.planning_phase(current_plan, available_agents)
                
                # Planning Phase ê²°ê³¼ ê²€ì¦
                original_task_count = len(current_plan.get("work_breakdown", []))
                improved_task_count = len(proposed_improved_plan.get("work_breakdown", []))
                
                if improved_task_count != original_task_count:
                    logger.warning(f"Planning Phaseê°€ ì‘ì—… ê°œìˆ˜ë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤: {original_task_count} â†’ {improved_task_count}")
                    logger.warning("ì›ë³¸ ê³„íšì„ ìœ ì§€í•©ë‹ˆë‹¤.")
                    improved_plan = current_plan
                else:
                    improved_plan = proposed_improved_plan
                
                # 2. Dispatcher: ì‘ì—…ì„ ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„
                logger.info("Starting dispatcher phase...")
                new_results = await self.dispatcher_phase(improved_plan, available_agents, execution_results)
                execution_results.update(new_results)
                logger.info(f"Dispatcher phase returned. Total execution results: {len(execution_results)}")
                
                # 3. Critic: ê²°ê³¼ ë¶„ì„ ë° ê°œì„ ì•ˆ ì œì‹œ
                logger.info("Starting critic phase...")
                critique_result = await self.critic_phase(execution_results, improved_plan)
                logger.info(f"Critic phase completed. Critique result: {critique_result}")

                # 4. ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•œ ê³„íš ì—…ë°ì´íŠ¸
                proposed_plan = critique_result.get("updated_plan", improved_plan)
                
                # ì‘ì—… ID ì¼ê´€ì„± ê²€ì¦
                current_task_ids = {task["id"] for task in improved_plan.get("work_breakdown", [])}
                proposed_task_ids = {task["id"] for task in proposed_plan.get("work_breakdown", [])}
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ ì‘ì—…ì˜ IDê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                processed_task_ids = set(execution_results.keys())
                id_conflicts = processed_task_ids - proposed_task_ids
                
                if id_conflicts:
                    logger.warning(f"Criticì´ ì´ë¯¸ ì²˜ë¦¬ëœ ì‘ì—… IDë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤: {id_conflicts}")
                    logger.warning("ê¸°ì¡´ ê³„íšì„ ìœ ì§€í•©ë‹ˆë‹¤.")
                    current_plan = improved_plan
                else:
                    current_plan = proposed_plan
                    
                logger.info(f"Updated plan: {current_plan}")

                # 5. ì™„ë£Œ ì¡°ê±´ í™•ì¸
                if critique_result.get("is_complete", False):
                    logger.info(f"Task completed after {iteration + 1} iterations")
                    break
                    
                iteration += 1
                
                # 6. ì ì‹œ ëŒ€ê¸° (ê³¼ë„í•œ API í˜¸ì¶œ ë°©ì§€)
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"Error in iteration {iteration + 1}: {e}")
                break
        
        logger.info(f"PDC cycle completed after {iteration} iterations (max: {max_iter})")
        
        return {
            # "final_plan": current_plan,
            "execution_results": execution_results,
            "iterations": iteration,
            "status": "completed" if iteration < max_iter else "max_iterations_reached"
        }

    async def planning_phase(self, current_plan: Dict[str, Any], available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê³„íš ë‹¨ê³„: í˜„ì¬ ê³„íšì„ ê²€í† í•˜ê³  ê°œì„ """
        
        # Planning Prompt í•„ìˆ˜ ì—°ê²° í™•ì¸
        if not hasattr(self, 'planning_prompt') or not self.planning_prompt:
            msg = "Planning Promptê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Prompt Template ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
        
        logger.info("Using external planning prompt from Prompt Component")
        planning_prompt = create_prompt_from_component(
            self.planning_prompt,
            default_system_message="ë‹¹ì‹ ì€ ì‘ì—… ê³„íšì„ ê²€í† í•˜ê³  ê°œì„ í•˜ëŠ” ê³„íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        )
        
        if planning_prompt is None:
            msg = "Planning Prompt ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
        
        # LLMì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ í˜„ì¬ ê³„íš ë°˜í™˜
        if not hasattr(self, 'llm') or self.llm is None:
            logger.warning("LLM not available for planning phase, using current plan")
            return current_plan

        try:
            chain = planning_prompt | self.llm | JsonOutputParser()
            result = await chain.ainvoke({
                "current_plan": json.dumps(current_plan, ensure_ascii=False, indent=2),
                "available_agents": json.dumps(available_agents, ensure_ascii=False, indent=2)
            })
            return result
        except Exception as e:
            logger.warning(f"Planning phase failed: {e}, using current plan")
            return current_plan

    async def dispatcher_phase(self, plan: Dict[str, Any], available_agents: List[Dict[str, Any]], existing_results: Dict[str, Any] = None) -> Dict[str, Any]:
        """ë””ìŠ¤íŒ¨ì²˜ ë‹¨ê³„: ì‘ì—…ì„ ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„"""
        
        # ê¸°ì¡´ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì‹œì‘
        if existing_results is None:
            existing_results = {}
        
        new_execution_results = {}
        
        # ë””ë²„ê¹…: í˜„ì¬ ìƒíƒœ ë¡œê·¸
        all_tasks = plan.get("work_breakdown", [])
        logger.info(f"Dispatcher: ì´ {len(all_tasks)}ê°œ ì‘ì—…, ê¸°ì¡´ ê²°ê³¼: {list(existing_results.keys()) if existing_results else 'ì—†ìŒ'}")
        
        # ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì²« ë²ˆì§¸ ì‘ì—…ë§Œ ì²˜ë¦¬
        for task in all_tasks:
            task_id = task["id"]
            agent_id = task["agent"]
            
            logger.info(f"Dispatcher: ì‘ì—… {task_id} í™•ì¸ ì¤‘... (ì—ì´ì „íŠ¸: {agent_id})")
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ ì‘ì—…ì€ ê±´ë„ˆë›°ê¸°
            if task_id in existing_results:
                logger.info(f"Task {task_id} already processed, skipping")
                continue
                
            logger.info(f"Processing task {task_id} with agent {agent_id}")
            
            # ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ í˜„ì¬ ì‘ì—…ì˜ í•„ìš” ì¶œë ¥ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            required_outputs = task.get("outputs", [])
            if required_outputs and existing_results:
                available_outputs = self.extract_available_outputs(existing_results)
                if all(output in available_outputs for output in required_outputs):
                    logger.info(f"Task {task_id} ìŠ¤í‚µ: í•„ìš”í•œ ì¶œë ¥ {required_outputs}ì´ ì´ë¯¸ ì´ì „ ì‘ì—…ì—ì„œ ìƒì„±ë¨")
                    # ì´ì „ ê²°ê³¼ì—ì„œ í•´ë‹¹ ì¶œë ¥ì„ ê°€ì ¸ì™€ì„œ ê²°ê³¼ë¡œ ì„¤ì •
                    combined_result = self.combine_previous_outputs(existing_results, required_outputs)
                    new_execution_results[task_id] = {
                        "status": "skipped",
                        "result": combined_result,
                        "agent": "previous_results",
                        "reason": f"Required outputs {required_outputs} already available from previous tasks"
                    }
                    logger.info(f"Task {task_id} added as skipped: {new_execution_results[task_id]}")
                    break
            
            try:
                # ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—… ìœ„ì„
                if agent_id != "self":
                    logger.info(f"Delegating task {task_id} to agent {agent_id}")
                    result = await self.delegate_task_to_agent(task, agent_id, available_agents)
                    logger.info(f"Task {task_id} delegation result: {result}")
                else:
                    # ì§ì ‘ ì‹¤í–‰
                    logger.info(f"Executing task {task_id} directly")
                    result = await self.execute_task_directly(task, existing_results)
                    logger.info(f"Task {task_id} direct execution result: {result}")
                
                new_execution_results[task_id] = {
                    "status": "completed",
                    "result": result,
                    "agent": agent_id
                }
                
                logger.info(f"Task {task_id} added to new_execution_results: {new_execution_results[task_id]}")
                
                # í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…ë§Œ ì²˜ë¦¬í•˜ê³  ë°˜í™˜ (PDC ì‚¬ì´í´ì„ ìœ„í•´)
                break
                
            except Exception as e:
                logger.error(f"Task {task_id} execution failed: {e}")
                new_execution_results[task_id] = {
                    "status": "failed",
                    "error": str(e),
                    "agent": agent_id
                }
                # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ í•œ ë²ˆì— í•˜ë‚˜ë§Œ ì²˜ë¦¬
                break
        
        # ëª¨ë“  ì‘ì—…ì„ í™•ì¸í–ˆì§€ë§Œ ì²˜ë¦¬í•  ê²ƒì´ ì—†ëŠ” ê²½ìš°
        if len(new_execution_results) == 0:
            logger.info(f"Dispatcher: ì²˜ë¦¬í•  ìƒˆë¡œìš´ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. (ì´ {len(all_tasks)}ê°œ ì‘ì—… ì¤‘ {len(existing_results)}ê°œ ì™„ë£Œ)")
        
        logger.info(f"Dispatcher phase completed. Returning {len(new_execution_results)} new results")
        return new_execution_results

    def extract_available_outputs(self, execution_results: Dict[str, Any]) -> List[str]:
        """ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥ ëª©ë¡ì„ ì¶”ì¶œ"""
        available_outputs = []
        
        for task_id, result in execution_results.items():
            if result.get("status") == "completed" and "agent_response" in result:
                agent_response = result["agent_response"]
                if "result" in agent_response and "parts" in agent_response["result"]:
                    # ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ì¶œë ¥ ìœ í˜•ì„ ì¶”ì •
                    for part in agent_response["result"]["parts"]:
                        if "text" in part:
                            text = part["text"].lower()
                            # ì¼ë°˜ì ì¸ ì¶œë ¥ íŒ¨í„´ ê°ì§€
                            if "ë‹¨ì–´" in text and ("ìˆ˜" in text or "ê°œìˆ˜" in text):
                                available_outputs.append("ë‹¨ì–´ ìˆ˜")
                                available_outputs.append("ë‹¨ì–´ ëª©ë¡")
                            if "í† í°" in text and ("ìˆ˜" in text or "ê°œìˆ˜" in text):
                                available_outputs.append("í† í° ìˆ˜")
                                available_outputs.append("í† í° ëª©ë¡")
                            if "ì„±ê²©" in text or "ê°ì •" in text:
                                available_outputs.append("ë¬¸ì¥ ì„±ê²©")
        
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥: {available_outputs}")
        return available_outputs

    def combine_previous_outputs(self, execution_results: Dict[str, Any], required_outputs: List[str]) -> Dict[str, Any]:
        """ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì¶œë ¥ë“¤ì„ ì¡°í•©í•˜ì—¬ ë°˜í™˜"""
        combined_result = {
            "task_id": "combined_from_previous",
            "agent_id": "result_combiner",
            "status": "completed",
            "timestamp": "2024-01-01T00:00:00Z",
            "agent_response": {
                "jsonrpc": "2.0",
                "id": "combined",
                "result": {
                    "kind": "message",
                    "messageId": str(uuid4()),
                    "role": "agent",
                    "parts": [{
                        "kind": "text",
                        "text": f"ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì¶œë ¥ {required_outputs}ì„ ì¡°í•©í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
                    }]
                }
            }
        }
        
        return combined_result

    async def execute_task_directly(self, task: Dict[str, Any], existing_results: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì§ì ‘ ì‹¤í–‰: ìˆ˜í•™ ê³„ì‚° ë“± ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—…"""
        
        task_id = task["id"]
        task_title = task["title"]
        task_inputs = task.get("inputs", [])
        task_outputs = task.get("outputs", [])
        
        logger.info(f"ì§ì ‘ ì‹¤í–‰ ì‘ì—…: {task_title}")
        logger.info(f"í•„ìš”í•œ ì…ë ¥: {task_inputs}")
        logger.info(f"ê¸°ëŒ€ ì¶œë ¥: {task_outputs}")
        
        # ìˆ˜í•™ ê³„ì‚° ì‘ì—… ì²˜ë¦¬
        if "ìˆ˜í•™ ê³„ì‚°" in task_title or "ê³±ì…ˆ" in task_title or "ìì—°ë¡œê·¸" in task_title:
            if existing_results:
                # ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
                word_count = None
                token_count = None
                
                for prev_task_id, prev_result in existing_results.items():
                    if prev_result.get("status") == "completed":
                        result_data = prev_result.get("result", {})
                        if isinstance(result_data, dict) and "agent_response" in result_data:
                            # A2A ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
                            agent_response = result_data["agent_response"]
                            if isinstance(agent_response, dict) and "result" in agent_response:
                                response_text = agent_response["result"]
                                if isinstance(response_text, dict) and "parts" in response_text:
                                    for part in response_text["parts"]:
                                        if part.get("kind") == "text":
                                            text_content = part.get("text", "")
                                            # í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ ìˆ˜ì™€ í† í° ìˆ˜ ì¶”ì¶œ
                                            import re
                                            word_match = re.search(r'ë‹¨ì–´.*?(\d+)', text_content)
                                            token_match = re.search(r'í† í°.*?(\d+)', text_content)
                                            
                                            if word_match:
                                                word_count = int(word_match.group(1))
                                            if token_match:
                                                token_count = int(token_match.group(1))
                
                if word_count is not None and token_count is not None:
                    import math
                    product = word_count * token_count
                    natural_log = math.log(product)
                    
                    result = {
                        "task_id": task_id,
                        "execution_method": "direct_calculation",
                        "inputs": {
                            "word_count": word_count,
                            "token_count": token_count
                        },
                        "calculation": {
                            "product": product,
                            "natural_log": natural_log
                        },
                        "result": f"ë‹¨ì–´ ìˆ˜({word_count}) Ã— í† í° ìˆ˜({token_count}) = {product}, ln({product}) = {natural_log:.6f}"
                    }
                    logger.info(f"ìˆ˜í•™ ê³„ì‚° ì™„ë£Œ: {result['result']}")
                    return result
                else:
                    logger.warning(f"ì´ì „ ì‘ì—… ê²°ê³¼ì—ì„œ ë‹¨ì–´ ìˆ˜({word_count}) ë˜ëŠ” í† í° ìˆ˜({token_count})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                logger.warning("ìˆ˜í•™ ê³„ì‚°ì„ ìœ„í•œ ì´ì „ ì‘ì—… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¼ë°˜ì ì¸ ì‘ì—… ì²˜ë¦¬
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
            user_input = self.input_value.content if hasattr(self.input_value, 'content') else str(self.input_value)
            
            # ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
            if "ë¶„ì„" in task_title or "í…ìŠ¤íŠ¸" in task_title:
                return await self.handle_text_analysis_task(task, user_input)
            elif "ì§ˆë¬¸" in task_title or "ë‹µë³€" in task_title or "QA" in task_title:
                return await self.handle_qa_task(task, user_input)
            elif "ìš”ì•½" in task_title or "ì •ë¦¬" in task_title:
                return await self.handle_summary_task(task, user_input)
            elif "ìƒì„±" in task_title or "ì‘ì„±" in task_title:
                return await self.handle_generation_task(task, user_input)
            else:
                # ê¸°ë³¸ ì²˜ë¦¬: LLMì„ ì‚¬ìš©í•œ ì¼ë°˜ì ì¸ ëŒ€ì‘
                return await self.handle_general_task(task, user_input)
                
        except Exception as e:
            logger.error(f"ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "task_id": task_id,
                "execution_method": "direct",
                "status": "error",
                "error": str(e),
                "result": f"ì‘ì—… '{task_title}' ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }

    async def handle_text_analysis_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ì„ ì‘ì—… ì²˜ë¦¬"""
        logger.info("í…ìŠ¤íŠ¸ ë¶„ì„ ì‘ì—… ì‹¤í–‰")
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ ìˆ˜í–‰
        word_count = len(user_input.split())
        char_count = len(user_input)
        char_count_no_spaces = len(user_input.replace(' ', ''))
        
        # ë¬¸ì¥ ìˆ˜ ê³„ì‚°
        import re
        sentences = re.split(r'[.!?]+', user_input)
        sentence_count = len([s for s in sentences if s.strip()])
        
        # ë‹¨ë½ ìˆ˜ ê³„ì‚°
        paragraphs = user_input.split('\n\n')
        paragraph_count = len([p for p in paragraphs if p.strip()])
        
        analysis_result = {
            "í…ìŠ¤íŠ¸": user_input[:100] + "..." if len(user_input) > 100 else user_input,
            "ë‹¨ì–´_ìˆ˜": word_count,
            "ë¬¸ì_ìˆ˜_ê³µë°±í¬í•¨": char_count,
            "ë¬¸ì_ìˆ˜_ê³µë°±ì œì™¸": char_count_no_spaces,
            "ë¬¸ì¥_ìˆ˜": sentence_count,
            "ë‹¨ë½_ìˆ˜": paragraph_count
        }
        
        result_text = f"""ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼:
        
ğŸ”¤ ë‹¨ì–´ ìˆ˜: {word_count}ê°œ
ğŸ“ ë¬¸ì ìˆ˜ (ê³µë°± í¬í•¨): {char_count}ê°œ
âœï¸ ë¬¸ì ìˆ˜ (ê³µë°± ì œì™¸): {char_count_no_spaces}ê°œ
ğŸ“„ ë¬¸ì¥ ìˆ˜: {sentence_count}ê°œ
ğŸ“‘ ë‹¨ë½ ìˆ˜: {paragraph_count}ê°œ

ğŸ“– ë¶„ì„ëœ í…ìŠ¤íŠ¸: "{user_input[:100]}{'...' if len(user_input) > 100 else ''}"
        """
        
        return {
            "task_id": task["id"],
            "execution_method": "text_analysis",
            "status": "completed",
            "analysis": analysis_result,
            "result": result_text
        }

    async def handle_qa_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """ì§ˆì˜ì‘ë‹µ ì‘ì—… ì²˜ë¦¬"""
        logger.info("ì§ˆì˜ì‘ë‹µ ì‘ì—… ì‹¤í–‰")
        
        # LLMì´ ìˆëŠ” ê²½ìš° LLMì„ ì‚¬ìš©
        if hasattr(self, 'llm') and self.llm is not None:
            try:
                from langchain_core.messages import HumanMessage
                
                prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {user_input}

ë‹µë³€ì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                
                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                answer = response.content if hasattr(response, 'content') else str(response)
                
                return {
                    "task_id": task["id"],
                    "execution_method": "llm_qa",
                    "status": "completed",
                    "question": user_input,
                    "answer": answer,
                    "result": f"â“ ì§ˆë¬¸: {user_input}\n\nğŸ’¡ ë‹µë³€: {answer}"
                }
            except Exception as e:
                logger.error(f"LLM ì§ˆì˜ì‘ë‹µ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # LLMì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
        default_answer = f"'{user_input}'ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìœ„í•´ì„œëŠ” LLM ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        return {
            "task_id": task["id"],
            "execution_method": "default_qa",
            "status": "completed",
            "question": user_input,
            "answer": default_answer,
            "result": f"â“ ì§ˆë¬¸: {user_input}\n\nğŸ’¡ ë‹µë³€: {default_answer}"
        }

    async def handle_summary_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """ìš”ì•½ ì‘ì—… ì²˜ë¦¬"""
        logger.info("ìš”ì•½ ì‘ì—… ì‹¤í–‰")
        
        # LLMì´ ìˆëŠ” ê²½ìš° LLMì„ ì‚¬ìš©
        if hasattr(self, 'llm') and self.llm is not None:
            try:
                from langchain_core.messages import HumanMessage
                
                prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•µì‹¬ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì›ë³¸ í…ìŠ¤íŠ¸:
{user_input}

ìš”ì•½ì€ 3-5ê°œì˜ ì£¼ìš” í¬ì¸íŠ¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                
                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                summary = response.content if hasattr(response, 'content') else str(response)
                
                return {
                    "task_id": task["id"],
                    "execution_method": "llm_summary",
                    "status": "completed",
                    "original_text": user_input,
                    "summary": summary,
                    "result": f"ğŸ“„ ì›ë³¸ ê¸¸ì´: {len(user_input)}ì\n\nğŸ“ ìš”ì•½:\n{summary}"
                }
            except Exception as e:
                logger.error(f"LLM ìš”ì•½ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # LLMì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ìš”ì•½
        words = user_input.split()
        if len(words) > 50:
            # ì²« 30ë‹¨ì–´ì™€ ë§ˆì§€ë§‰ 20ë‹¨ì–´ë¡œ ê¸°ë³¸ ìš”ì•½
            summary = " ".join(words[:30]) + " ... " + " ".join(words[-20:])
        else:
            summary = user_input
        
        return {
            "task_id": task["id"],
            "execution_method": "basic_summary",
            "status": "completed",
            "original_text": user_input,
            "summary": summary,
            "result": f"ğŸ“„ ì›ë³¸ ê¸¸ì´: {len(user_input)}ì\n\nğŸ“ ê¸°ë³¸ ìš”ì•½:\n{summary}"
        }

    async def handle_generation_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """ìƒì„± ì‘ì—… ì²˜ë¦¬"""
        logger.info("ìƒì„± ì‘ì—… ì‹¤í–‰")
        
        # LLMì´ ìˆëŠ” ê²½ìš° LLMì„ ì‚¬ìš©
        if hasattr(self, 'llm') and self.llm is not None:
            try:
                from langchain_core.messages import HumanMessage
                
                prompt = f"""ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì˜ì ì´ê³  ìœ ìš©í•œ ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

ìš”ì²­: {user_input}

ì ì ˆí•œ í˜•ì‹ê³¼ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                
                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                generated_content = response.content if hasattr(response, 'content') else str(response)
                
                return {
                    "task_id": task["id"],
                    "execution_method": "llm_generation",
                    "status": "completed",
                    "request": user_input,
                    "generated_content": generated_content,
                    "result": f"ğŸ¯ ìš”ì²­: {user_input}\n\nâœ¨ ìƒì„±ëœ ë‚´ìš©:\n{generated_content}"
                }
            except Exception as e:
                logger.error(f"LLM ìƒì„± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # LLMì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
        default_content = f"'{user_input}' ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ë” ì •êµí•œ ìƒì„±ì„ ìœ„í•´ì„œëŠ” LLM ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        return {
            "task_id": task["id"],
            "execution_method": "default_generation",
            "status": "completed",
            "request": user_input,
            "generated_content": default_content,
            "result": f"ğŸ¯ ìš”ì²­: {user_input}\n\nâœ¨ ê¸°ë³¸ ì‘ë‹µ:\n{default_content}"
        }

    async def handle_general_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ ì‘ì—… ì²˜ë¦¬"""
        logger.info("ì¼ë°˜ ì‘ì—… ì‹¤í–‰")
        
        # ê¸°ë³¸ì ì¸ ì‘ì—… ì²˜ë¦¬
        task_description = task.get("title", "ì¼ë°˜ ì‘ì—…")
        
        # LLMì´ ìˆëŠ” ê²½ìš° LLMì„ ì‚¬ìš©
        if hasattr(self, 'llm') and self.llm is not None:
            try:
                from langchain_core.messages import HumanMessage
                
                prompt = f"""ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

ì‘ì—…: {task_description}
ì‚¬ìš©ì ì…ë ¥: {user_input}

ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ì‘ì—…ì„ ì™„ë£Œí•˜ê³  ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
                
                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                result_content = response.content if hasattr(response, 'content') else str(response)
                
                return {
                    "task_id": task["id"],
                    "execution_method": "llm_general",
                    "status": "completed",
                    "task_description": task_description,
                    "user_input": user_input,
                    "result": f"ğŸ”§ ì‘ì—…: {task_description}\nğŸ“ ì…ë ¥: {user_input}\n\nâœ… ê²°ê³¼:\n{result_content}"
                }
            except Exception as e:
                logger.error(f"LLM ì¼ë°˜ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # LLMì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        result_content = f"'{task_description}' ì‘ì—…ì„ '{user_input}' ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë” ì •êµí•œ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” LLM ëª¨ë¸ì´ë‚˜ ì „ìš© ë„êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        
        return {
            "task_id": task["id"],
            "execution_method": "basic_general",
            "status": "completed",
            "task_description": task_description,
            "user_input": user_input,
            "result": f"ğŸ”§ ì‘ì—…: {task_description}\nğŸ“ ì…ë ¥: {user_input}\n\nâœ… ê¸°ë³¸ ì²˜ë¦¬ ê²°ê³¼:\n{result_content}"
        }

    async def delegate_task_to_agent(self, task: Dict[str, Any], agent_id: str, available_agents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """íŠ¹ì • ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„"""
        
        logger.info(f"Delegating task {task['id']} to agent {agent_id}")
        logger.info(f">> Task : {task['title']}")
        logger.info(f">> Task Debug: {task}")  # ë””ë²„ê¹…: ì „ì²´ task ì •ë³´ ì¶œë ¥
        
        logger.info(f">> Available Agents : {len(available_agents)}")
        
        # ê³„íšì—ì„œ ì´ë¯¸ í• ë‹¹ëœ ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ ë§¤ì¹­ (ì—ì´ì „íŠ¸ í‰ê°€ ë‹¨ê³„ëŠ” Work Planì—ì„œ ì™„ë£Œë¨)
        logger.info(f"Finding pre-assigned agent: {agent_id}")
        target_agent = None
        
        for agent in available_agents:
            if agent.get("id") == agent_id:
                target_agent = agent
                logger.info(f"Found target agent: {agent.get('name', agent_id)}")
                break
        
        if not target_agent:
            logger.error(f"Pre-assigned agent '{agent_id}' not found in available agents")
            return {
                "task_id": task["id"],
                "agent_id": agent_id,
                "status": "failed",
                "error": f"Pre-assigned agent '{agent_id}' not found in available agents",
                "timestamp": "2024-01-01T00:00:00Z"
            }
        
        # ì—ì´ì „íŠ¸ URL í™•ì¸ ë° ë³€í™˜
        agent_url = target_agent.get("url") or target_agent.get("endpoint")
        if not agent_url:
            agent_name = target_agent.get("name", target_agent.get("id", "Unknown"))
            msg = f"ì„ íƒëœ ì—ì´ì „íŠ¸ '{agent_name}' (ID: {target_agent.get('id', 'Unknown')})ì— URLì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
        
        # 0.0.0.0ì„ 127.0.0.1ë¡œ ë³€í™˜ (í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œìš©)
        if "0.0.0.0" in agent_url:
            agent_url = agent_url.replace("0.0.0.0", "127.0.0.1")
            logger.info(f"Converted 0.0.0.0 to 127.0.0.1: {agent_url}")
        
        # A2A í”„ë¡œí† ì½œì— ë§ëŠ” ì‹¤ì œ API í˜¸ì¶œ
        try:
            logger.info(f"Calling A2A API: {agent_url}")
            
            # A2A JSON-RPC 2.0 í”„ë¡œí† ì½œ í˜ì´ë¡œë“œ êµ¬ì„±
            a2a_rpc_payload = {
                "jsonrpc": "2.0",
                "id": task["id"],
                "method": "invoke",
                "params": {
                    "message": {
                        "message_id": task["id"],
                        "role": "user",
                        "parts": [
                            {
                                "kind": "text",
                                "text": f"Task: {task['title']}\nDescription: {task.get('description', '')}\nInputs: {', '.join(task.get('inputs', []))}\nExpected Outputs: {', '.join(task.get('outputs', []))}"
                            }
                        ]
                    },
                    "stream": False  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
                }
            }
            
            # HTTP í—¤ë” ì„¤ì •
            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json",
                "User-Agent": "A2A-Agent-Component/1.0"
            }
            
            logger.info(f"A2A RPC payload: {a2a_rpc_payload}")
            
            # A2A í‘œì¤€ API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    agent_url,
                    json=a2a_rpc_payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    logger.info(f"A2A API response status: {response.status}")
                    
                    if response.status == 200:
                        try:
                            result_data = await response.json()
                            logger.info(f"Task {task['id']} successfully delegated to agent {agent_id}")
                            
                            # JSON-RPC 2.0 ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬
                            if "result" in result_data:
                                rpc_result = result_data["result"]
                                # ì‘ë‹µ ìˆ˜ì‹  í™•ì¸ ë¡œê·¸
                                logger.info(f"Agent response received from {agent_id}")
                                
                                final_result = {
                                    "task_id": task["id"],
                                    "agent_id": agent_id,
                                    "status": "completed",
                                    "timestamp": "2024-01-01T00:00:00Z",
                                    "agent_response": result_data
                                }
                                return final_result
                            elif "error" in result_data:
                                logger.error(f"Found 'error' in response: {result_data['error']}")
                                return {
                                    "task_id": task["id"],
                                    "agent_id": agent_id,
                                    "status": "failed",
                                    "error": f"RPC Error: {result_data['error']}",
                                    "timestamp": "2024-01-01T00:00:00Z"
                                }
                            else:
                                logger.warning(f"No 'result' or 'error' found in response, using raw data")
                                return {
                                    "task_id": task["id"],
                                    "agent_id": agent_id,
                                    "status": "completed",
                                    "result": result_data,
                                    "timestamp": "2024-01-01T00:00:00Z",
                                    "agent_response": result_data
                                }
                        except Exception as json_error:
                            logger.error(f"Error parsing JSON response: {json_error}")
                            response_text = await response.text()
                            logger.error(f"Raw response text: {response_text}")
                            return {
                                "task_id": task["id"],
                                "agent_id": agent_id,
                                "status": "failed",
                                "error": f"JSON parsing error: {json_error}",
                                "timestamp": "2024-01-01T00:00:00Z"
                            }
                    else:
                        error_text = await response.text()
                        logger.error(f"Agent {agent_id} returned error: {response.status} - {error_text}")
                        
                        return {
                            "task_id": task["id"],
                            "agent_id": agent_id,
                            "status": "failed",
                            "error": f"Agent returned HTTP {response.status}: {error_text}",
                            "timestamp": "2024-01-01T00:00:00Z"
                        }
                        
        except asyncio.TimeoutError:
            logger.error(f"Timeout while delegating task {task['id']} to agent {agent_id}")
            return {
                "task_id": task["id"],
                "agent_id": agent_id,
                "status": "timeout",
                "error": "Request timeout",
                "timestamp": "2024-01-01T00:00:00Z"
            }
        except Exception as e:
            logger.error(f"Error delegating task {task['id']} to agent {agent_id}: {e}")
            return {
                "task_id": task["id"],
                "agent_id": agent_id,
                "status": "error",
                "error": str(e),
                "timestamp": "2024-01-01T00:00:00Z"
            }



    async def critic_phase(self, execution_results: Dict[str, Any], current_plan: Dict[str, Any]) -> Dict[str, Any]:
        """ë¹„í‰ ë‹¨ê³„: ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ê°œì„ ì•ˆ ì œì‹œ"""
        
        logger.info("=== CRITIC PHASE STARTED ===")
        logger.info(f"Analyzing {len(execution_results)} execution results")
        
        # Critic Prompt í•„ìˆ˜ ì—°ê²° í™•ì¸
        if not hasattr(self, 'critic_prompt') or not self.critic_prompt:
            msg = "Critic Promptê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Prompt Template ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
        
        logger.info("Using external critic prompt from Prompt Component for LLM-based analysis")
        return await self._llm_based_critic(execution_results, current_plan)
    
    async def _llm_based_critic(self, execution_results: Dict[str, Any], current_plan: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ë¹„í‰ ë¶„ì„"""
        
        # ì™¸ë¶€ Prompt Component ì‚¬ìš©
        critic_prompt = create_prompt_from_component(
            self.critic_prompt,
            default_system_message="ë‹¹ì‹ ì€ ì‘ì—… ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ê°œì„ ì•ˆì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ë¹„í‰ê°€ì…ë‹ˆë‹¤."
        )
        
        if critic_prompt is None:
            msg = "Critic Prompt ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì—°ê²°í•´ì£¼ì„¸ìš”."
            logger.error(msg)
            raise ValueError(msg)
        
        try:
            # ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ìƒì„±
            total_tasks = len(current_plan.get("work_breakdown", []))
            completed_tasks = sum(1 for result in execution_results.values() if result.get("status") == "completed")
            failed_tasks = sum(1 for result in execution_results.values() if result.get("status") == "failed")
            
            # í˜„ì¬ ì§„í–‰ ìƒí™© ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            all_task_ids = [task["id"] for task in current_plan.get("work_breakdown", [])]
            completed_task_ids = [task_id for task_id, result in execution_results.items() if result.get("status") == "completed"]
            pending_task_ids = [task_id for task_id in all_task_ids if task_id not in execution_results]
            
            task_summary = {
                "total": total_tasks,
                "completed": completed_tasks,
                "failed": failed_tasks,
                "completion_rate": f"{completed_tasks}/{total_tasks}",
                "execution_context": {
                    "mode": "ìˆœì°¨ ì‹¤í–‰ (PDC ì‚¬ì´í´)",
                    "current_status": f"í˜„ì¬ê¹Œì§€ {completed_tasks}ê°œ ì‘ì—… ì™„ë£Œ, {len(pending_task_ids)}ê°œ ì‘ì—… ëŒ€ê¸° ì¤‘",
                    "completed_tasks": completed_task_ids,
                    "pending_tasks": pending_task_ids,
                    "note": "ì‘ì—…ì€ í•œ ë²ˆì— í•˜ë‚˜ì”© ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ë©°, ê° ì‘ì—… ì™„ë£Œ í›„ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
                }
            }
            
            # ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ - í° ì‘ë‹µ ë°ì´í„° ì²˜ë¦¬
            logger.info(f"Processing {len(execution_results)} execution results for critic analysis")
            summarized_results = {}
            for task_id, result in execution_results.items():
                logger.info(f"Processing result for task {task_id}: keys={list(result.keys())}")
                
                # execution_resultsì˜ ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬
                # result = {'status': 'completed', 'result': {...actual_data...}, 'agent': '...'}
                actual_result = result.get("result", result)  # ì¤‘ì²©ëœ result êµ¬ì¡° í•´ê²°
                
                summary = {
                    "task_id": actual_result.get("task_id", task_id),
                    "agent_id": actual_result.get("agent_id", result.get("agent", "unknown")),
                    "status": actual_result.get("status", result.get("status", "unknown")),
                    "timestamp": actual_result.get("timestamp", "unknown")
                }
                
                # result ë°ì´í„° ì²˜ë¦¬ (A2A ì—ì´ì „íŠ¸ ì‘ë‹µ ë˜ëŠ” ì§ì ‘ ê³„ì‚° ê²°ê³¼)
                has_agent_response = "agent_response" in actual_result
                has_result_in_response = has_agent_response and actual_result["agent_response"] and "result" in actual_result["agent_response"]
                has_direct_result = "result" in actual_result and "execution_method" in actual_result
                
                logger.info(f"Task {task_id} - has_agent_response: {has_agent_response}, has_result_in_response: {has_result_in_response}")
                logger.info(f"Task {task_id} - has_direct_result: {has_direct_result}")
                
                if has_result_in_response:
                    # A2A ì—ì´ì „íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                    agent_result = actual_result["agent_response"]["result"]
                    result_str = str(agent_result)
                    summary["result_preview"] = result_str[:200] + "..." if len(result_str) > 200 else result_str
                    summary["result_size"] = len(result_str)
                    logger.info(f"Task {task_id} - result_size: {len(result_str)}")
                elif has_direct_result:
                    # ì§ì ‘ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ (ìˆ˜í•™ ê³„ì‚° ë“±)
                    direct_result = actual_result["result"]
                    result_str = str(direct_result)
                    summary["result_preview"] = result_str[:200] + "..." if len(result_str) > 200 else result_str
                    summary["result_size"] = len(result_str)
                    summary["execution_method"] = actual_result.get("execution_method", "direct")
                    logger.info(f"Task {task_id} - direct result_size: {len(result_str)}")
                else:
                    summary["result_preview"] = "No result data"
                    logger.warning(f"Task {task_id} - No result data found")
                
                if "error" in result:
                    summary["error"] = result["error"]
                    
                summarized_results[task_id] = summary
            
            # LLMì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë¹„í‰ ì‚¬ìš©
            if not hasattr(self, 'llm') or self.llm is None:
                logger.warning("LLM not available for critic phase, using heuristic critic")
                return await self._heuristic_based_critic(execution_results, current_plan)

            chain = critic_prompt | self.llm | JsonOutputParser()
            result = await chain.ainvoke({
                "execution_results": json.dumps(summarized_results, ensure_ascii=False, indent=2),
                "current_plan": json.dumps(current_plan, ensure_ascii=False, indent=2),
                "task_summary": json.dumps(task_summary, ensure_ascii=False, indent=2)
            })
            
            # ê¸°ë³¸ê°’ ë³´ì¥
            if "is_complete" not in result:
                result["is_complete"] = (completed_tasks == total_tasks) and (failed_tasks == 0)
            if "updated_plan" not in result:
                result["updated_plan"] = current_plan
            if "next_actions" not in result:
                result["next_actions"] = ["ê³„ì† ì§„í–‰"]
                
            logger.info("LLM-based critic analysis completed")
            return result
            
        except Exception as e:
            logger.error(f"LLM critic analysis failed: {e}, falling back to heuristic")
            return await self._heuristic_based_critic(execution_results, current_plan)
    
    async def _heuristic_based_critic(self, execution_results: Dict[str, Any], current_plan: Dict[str, Any]) -> Dict[str, Any]:
        """íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë¹„í‰ ë¶„ì„ (ê¸°ì¡´ ë¡œì§)"""
        
        # ì‹¤í–‰ ê²°ê³¼ ë¶„ì„
        total_tasks = len(current_plan.get("work_breakdown", []))
        completed_tasks = 0
        failed_tasks = 0
        
        for task_id, result in execution_results.items():
            if result.get("status") == "completed":
                completed_tasks += 1
            elif result.get("status") == "failed":
                failed_tasks += 1
        
        logger.info(f"Task analysis: {completed_tasks}/{total_tasks} completed, {failed_tasks} failed")
        
        # ì™„ë£Œ ì¡°ê±´ íŒë‹¨
        is_complete = (completed_tasks == total_tasks) and (failed_tasks == 0)
        
        # ê°„ë‹¨í•œ ë¹„í‰ ìƒì„±
        if is_complete:
            critique = f"ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ({completed_tasks}/{total_tasks} ì™„ë£Œ)"
            next_actions = ["ì‘ì—… ì™„ë£Œ"]
        elif failed_tasks > 0:
            critique = f"ì¼ë¶€ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({failed_tasks}ê°œ ì‹¤íŒ¨, {completed_tasks}ê°œ ì™„ë£Œ)"
            next_actions = ["ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì‹œë„", "ì˜¤ë¥˜ ì›ì¸ ë¶„ì„"]
        else:
            critique = f"ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ({completed_tasks}/{total_tasks} ì™„ë£Œ)"
            next_actions = ["ë‚¨ì€ ì‘ì—… ê³„ì† ì§„í–‰"]
        
        result = {
            "critique": critique,
            "updated_plan": current_plan,  # í˜„ì¬ ê³„íš ìœ ì§€
            "is_complete": is_complete,
            "next_actions": next_actions,
            "task_summary": {
                "total": total_tasks,
                "completed": completed_tasks,
                "failed": failed_tasks
            }
        }
        
        logger.info(f"Heuristic critic phase result: {result}")
        return result

    async def get_memory_data(self):
        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.
        messages = (
            await MemoryComponent(**self.get_base_args())
            .set(session_id=self.graph.session_id, order="Ascending", n_messages=self.n_messages)
            .retrieve_messages()
        )
        return [
            message for message in messages if getattr(message, "id", None) != getattr(self.input_value, "id", None)
        ]

    def get_llm(self):
        if not isinstance(self.agent_llm, str):
            return self.agent_llm, None

        try:
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if not provider_info:
                msg = f"Invalid model provider: {self.agent_llm}"
                raise ValueError(msg)

            component_class = provider_info.get("component_class")
            display_name = component_class.display_name
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix", "")

            return self._build_llm_model(component_class, inputs, prefix), display_name

        except Exception as e:
            logger.error(f"Error building {self.agent_llm} language model: {e!s}")
            msg = f"Failed to initialize language model: {e!s}"
            raise ValueError(msg) from e

    def _build_llm_model(self, component, inputs, prefix=""):
        model_kwargs = {}
        for input_ in inputs:
            if hasattr(self, f"{prefix}{input_.name}"):
                model_kwargs[input_.name] = getattr(self, f"{prefix}{input_.name}")
        return component.set(**model_kwargs).build_model()

    def set_component_params(self, component):
        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
        if provider_info:
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix")
            model_kwargs = {input_.name: getattr(self, f"{prefix}{input_.name}") for input_ in inputs}

            return component.set(**model_kwargs)
        return component

    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:
        """Delete specified fields from build_config."""
        for field in fields:
            build_config.pop(field, None)

    def update_input_types(self, build_config: dotdict) -> dotdict:
        """Update input types for all fields in build_config."""
        for key, value in build_config.items():
            if isinstance(value, dict):
                if value.get("input_types") is None:
                    build_config[key]["input_types"] = []
                # agent_llmì˜ input_typesë¥¼ LanguageModelìœ¼ë¡œ ê°•ì œ ì„¤ì •
                if key == "agent_llm":
                    build_config[key]["input_types"] = ["LanguageModel"]
            elif hasattr(value, "input_types") and value.input_types is None:
                value.input_types = []
                # agent_llmì˜ input_typesë¥¼ LanguageModelìœ¼ë¡œ ê°•ì œ ì„¤ì •
                if key == "agent_llm":
                    value.input_types = ["LanguageModel"]
        return build_config

    async def update_build_config(
        self, build_config: dotdict, field_value: str, field_name: str | None = None
    ) -> dotdict:
        # Iterate over all providers in the MODEL_PROVIDERS_DICT
        # Existing logic for updating build_config
        if field_name in ("agent_llm",):
            build_config["agent_llm"]["value"] = field_value
            provider_info = MODEL_PROVIDERS_DICT.get(field_value)
            if provider_info:
                component_class = provider_info.get("component_class")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call the component class's update_build_config method
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )

            provider_configs: dict[str, tuple[dict, list[dict]]] = {
                provider: (
                    MODEL_PROVIDERS_DICT[provider]["fields"],
                    [
                        MODEL_PROVIDERS_DICT[other_provider]["fields"]
                        for other_provider in MODEL_PROVIDERS_DICT
                        if other_provider != provider
                    ],
                )
                for provider in MODEL_PROVIDERS_DICT
            }
            if field_value in provider_configs:
                fields_to_add, fields_to_delete = provider_configs[field_value]

                # Delete fields from other providers
                for fields in fields_to_delete:
                    self.delete_fields(build_config, fields)

                # Add provider-specific fields
                if field_value == "OpenAI" and not any(field in build_config for field in fields_to_add):
                    build_config.update(fields_to_add)
                else:
                    build_config.update(fields_to_add)
                # Reset input types for agent_llm
                build_config["agent_llm"]["input_types"] = ["LanguageModel"]
            elif field_value == "Custom":
                # Delete all provider fields
                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)
                # Update with custom component
                custom_component = DropdownInput(
                    name="agent_llm",
                    display_name="Language Model",
                    options=[*sorted(MODEL_PROVIDERS), "Custom"],
                    value="Custom",
                    real_time_refresh=True,
                    input_types=["LanguageModel"],
                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]
                    + [{"icon": "brain"}],
                )
                build_config.update({"agent_llm": custom_component.to_dict()})
            # Update input types for all fields
            build_config = self.update_input_types(build_config)

            # Validate required keys
            default_keys = [
                "code",
                "_type",
                "agent_llm",
                "tools",
                "input_value",
                "add_current_date_tool",
                "system_prompt",
                "agent_description",
                "a2a_max_iterations",
                "handle_parsing_errors",
                "verbose",
                "work_plan_prompt",
                "planning_prompt", 

                "critic_prompt",
            ]
            
            # ëˆ„ë½ëœ í•„ìˆ˜ í‚¤ë“¤ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if "tools" not in build_config:
                build_config["tools"] = {"value": "", "input_types": ["Tool"]}
            if "input_value" not in build_config:
                build_config["input_value"] = {"value": "", "input_types": ["Message"]}
            if "agent_description" not in build_config:
                build_config["agent_description"] = {"value": "A helpful assistant with access to the following tools:"}
            if "work_plan_prompt" not in build_config:
                build_config["work_plan_prompt"] = {"value": None, "input_types": ["Message"]}
            if "planning_prompt" not in build_config:
                build_config["planning_prompt"] = {"value": None, "input_types": ["Message"]}

            if "critic_prompt" not in build_config:
                build_config["critic_prompt"] = {"value": None, "input_types": ["Message"]}
            
            missing_keys = [key for key in default_keys if key not in build_config]
            if missing_keys:
                msg = f"Missing required keys in build_config: {missing_keys}"
                raise ValueError(msg)
        if (
            isinstance(self.agent_llm, str)
            and self.agent_llm in MODEL_PROVIDERS_DICT
            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS
        ):
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if provider_info:
                component_class = provider_info.get("component_class")
                component_class = self.set_component_params(component_class)
                prefix = provider_info.get("prefix")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call each component class's update_build_config method
                    # remove the prefix from the field_name
                    if isinstance(field_name, str) and isinstance(prefix, str):
                        field_name = field_name.replace(prefix, "")
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )
        return dotdict({k: v.to_dict() if hasattr(v, "to_dict") else v for k, v in build_config.items()})



