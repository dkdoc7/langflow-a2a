from langchain_core.tools import StructuredTool

from langflow.base.agents.agent import LCToolsAgentComponent
from langflow.base.agents.events import ExceptionWithMessageError
from langflow.base.models.model_input_constants import (
    ALL_PROVIDER_FIELDS,
    MODEL_DYNAMIC_UPDATE_FIELDS,
    MODEL_PROVIDERS,
    MODEL_PROVIDERS_DICT,
    MODELS_METADATA,
)
from langflow.base.models.model_utils import get_model_name
from langflow.components.helpers.current_date import CurrentDateComponent
from langflow.components.helpers.memory import MemoryComponent
from langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent
from langflow.custom.utils import update_component_build_config
from langflow.io import HandleInput, BoolInput, DropdownInput, IntInput, MultilineInput, Output
from langflow.logging import logger
from langflow.schema.dotdict import dotdict
from langflow.schema.message import Message

from langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI
from langchain_core.messages import HumanMessage
import json
from typing import Any, Dict, List, Optional
import aiohttp

def set_advanced_true(component_input):
    component_input.advanced = True
    return component_input


MODEL_PROVIDERS_LIST = ["Anthropic", "Google Generative AI", "Groq", "OpenAI"]


class AgentComponent(ToolCallingAgentComponent):
    display_name: str = "Agent"
    description: str = "Define the agent's instructions, then enter a task to complete using tools."
    documentation: str = "https://docs.langflow.org/agents"
    icon = "bot"
    beta = False
    name = "Agent"

    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]

    inputs = [
        DropdownInput(
            name="agent_llm",
            display_name="Model Provider",
            info="The provider of the language model that the agent will use to generate responses.",
            options=[*MODEL_PROVIDERS_LIST, "Custom"],
            value="OpenAI",
            real_time_refresh=True,
            input_types=[],
            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST] + [{"icon": "brain"}],
        ),
        *MODEL_PROVIDERS_DICT["OpenAI"]["inputs"],
        MultilineInput(
            name="system_prompt",
            display_name="Agent Instructions",
            info="System Prompt: Initial instructions and context provided to guide the agent's behavior.",
            value="You are a helpful assistant that can use tools to answer questions and perform tasks.",
            advanced=False,
        ),
        IntInput(
            name="n_messages",
            display_name="Number of Chat History Messages",
            value=100,
            info="Number of chat history messages to retrieve.",
            advanced=True,
            show=True,
        ),

        #----------------------------------------------------
        HandleInput(
            name="execution_plan",
            display_name="Execution Plan",
            info="A2A Plannerì—ì„œ ìƒì„±ëœ ì‹¤í–‰ ê³„íš (JSON Message)",
            advanced=False,
            input_types=["Message"],
            required=True,
        ),

        BoolInput(
            name="verbose",
            display_name="Verbose",
            value=True,
            info="Whether to run in verbose mode.",
            advanced=True,
        ),
        MultilineInput(
            name="system_prompt",
            display_name="Delegator Instructions", 
            info="A2A Delegatorì˜ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­",
            value="""ë‹¹ì‹ ì€ A2A Discovery ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ì—¬ ì‹¤í–‰ ê³„íšì— ë”°ë¼ ìž‘ì—…ì„ ìœ„ìž„í•˜ê³  ê´€ë¦¬í•˜ëŠ” A2A Delegatorìž…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
1. A2A Plannerê°€ ìƒì„±í•œ ì‹¤í–‰ ê³„íš(execution_plan)ì„ ë¶„ì„
2. work_breakdownì—ì„œ ì˜ì¡´ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ê°€ëŠ¥í•œ ìž‘ì—… í•˜ë‚˜ë¥¼ ì„ íƒ
3. ê° ìž‘ì—… ì‹¤í–‰ ì „ ì‚°ì¶œë¬¼ì´ ì´ë¯¸ ë“±ë¡ë˜ì—ˆëŠ”ì§€ LLMìœ¼ë¡œ ê²€ì¦
4. ìž‘ì—… ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ì¶œë ¥ í¬íŠ¸ë¡œ A2A Critic ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
5. Criticì´ í‰ê°€ ê²°ê³¼ë¥¼ A2A Plannerì— í”¼ë“œë°±í•˜ì—¬ ê³„íš ì—…ë°ì´íŠ¸
6. ìˆœí™˜ êµ¬ì¡°: Planner â†’ Delegator â†’ Critic â†’ Planner â†’ Delegator...

ì‹¤í–‰ ì›ì¹™:
- ì˜ì¡´ì„± ê´€ê³„ë¥¼ ì¤€ìˆ˜í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ í•œ ë²ˆì— í•˜ë‚˜ì”© ìž‘ì—… ì‹¤í–‰
- ì‚°ì¶œë¬¼ì´ ì´ë¯¸ ì¡´ìž¬í•˜ë©´ ìž‘ì—… ìŠ¤í‚µí•˜ê³  ë‹¤ìŒ ìž‘ì—…ìœ¼ë¡œ ì´ë™
- ê° ìž‘ì—…ì˜ ê²°ê³¼ë¥¼ ì¶”ì í•˜ì—¬ ì „ì²´ ì§„í–‰ ìƒí™© ê´€ë¦¬
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì ˆí•œ ëŒ€ì‘ ë° ë¡œê¹…""",
            advanced=False,
        ),
        
        #----------------------------------------------------









        *LCToolsAgentComponent._base_inputs,
        # removed memory inputs from agent component
        # *memory_inputs,
        BoolInput(
            name="add_current_date_tool",
            display_name="Current Date",
            advanced=True,
            info="If true, will add a tool to the agent that returns the current date.",
            value=True,
        ),
    ]
    outputs = [
        Output(name="response", display_name="Execution Result", method="execute_plan")
    ]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Execution state for plan-delegation mode (optional)
        self.task_outputs: Dict[str, Any] = {}
        self.execution_history: List[Dict[str, Any]] = []
        self.completed_tasks: set[str] = set()

    async def execute_plan(self) -> Message:
        try:
            # Get LLM model and validate
            llm_model, display_name = self.get_llm()
            if llm_model is None:
                msg = "No language model selected. Please choose a model to proceed."
                raise ValueError(msg)
            self.model_name = get_model_name(llm_model, display_name=display_name)

            # Get memory data
            self.chat_history = await self.get_memory_data()
            if isinstance(self.chat_history, Message):
                self.chat_history = [self.chat_history]

            # Add current date tool if enabled
            if self.add_current_date_tool:
                if not isinstance(self.tools, list):  # type: ignore[has-type]
                    self.tools = []
                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)
                if not isinstance(current_date_tool, StructuredTool):
                    msg = "CurrentDateComponent must be converted to a StructuredTool"
                    raise TypeError(msg)
                self.tools.append(current_date_tool)
            # note the tools are not required to run the agent, hence the validation removed.

            # Set up and run agent
            self.set(
                llm=llm_model,
                tools=self.tools or [],
                chat_history=self.chat_history,
                input_value=self.input_value,
                system_prompt=self.system_prompt,
            )




            #----------------------------------------------------
            execution_plan = self.parse_execution_plan(self.execution_plan)
            work_breakdown = execution_plan.get('work_breakdown', [])
            
            if not work_breakdown:
                return Message(
                    text="No tasks found in execution plan",
                    sender=MESSAGE_SENDER_AI,
                    sender_name=MESSAGE_SENDER_NAME_AI,
                )

            logger.info(f"Starting task execution with {len(work_breakdown)} tasks")

            # í˜„ìž¬ ì‹¤í–‰ ê³„íšì—ì„œ ë‹¤ìŒ ì‹¤í–‰ ê°€ëŠ¥í•œ ìž‘ì—… í•˜ë‚˜ ì°¾ê¸°
            next_task = self.get_next_executable_task(work_breakdown)

            if not next_task:
                if self.all_tasks_completed(work_breakdown):
                    logger.info("All tasks completed successfully!")
                    final_result = {
                        "status": "completed",
                        "completed_tasks": list(self.completed_tasks),
                        "total_tasks": len(work_breakdown),
                        "task_outputs": self.task_outputs,
                        "execution_summary": self.execution_history
                    }
                else:
                    logger.warning("No executable tasks found but not all tasks completed")
                    final_result = {
                        "status": "deadlock",
                        "completed_tasks": list(self.completed_tasks),
                        "total_tasks": len(work_breakdown),
                        "task_outputs": self.task_outputs,
                        "execution_summary": self.execution_history
                    }
            else:
                # ë‹¤ìŒ ìž‘ì—… ì‹¤í–‰
                logger.info(f"Executing next task: {next_task.get('id')} - {next_task.get('title')}")

                try:                               
                    task_id = next_task.get('id')

                    # ì‚°ì¶œë¬¼ì´ ì´ë¯¸ ì¡´ìž¬í•˜ë©´ ìž‘ì—… ìŠ¤í‚µ
                    if await self.validate_output_exists(next_task):
                        result = {
                            "task_id": task_id,
                            "status": "skipped",
                            "reason": "Output already exists",
                            "outputs": next_task.get('outputs', []),
                            "task_outputs": next_task.get('outputs', []),
                            "outputs_completed": True,
                            "execution_time": 0
                        }
                        self.completed_tasks.add(task_id)
                        task_result = result

                    task_title = next_task.get('title', 'Unknown Task')
                    agent = next_task.get('agent', None)
                    agent_name = agent.get("name","Unknown") if agent else "Unknown"
                    task_result = None

                    # agentê°€ ì§€ì •ë˜ì—ˆê³  'self'ê°€ ì•„ë‹ˆë¼ë©´ ìž‘ì—… ìœ„ìž„
                    if agent and agent_name != 'self':
                        task_result = await self.delegate_to_agent(next_task, agent)
                    else:
                        agent = self.create_agent_runnable()
                        task_result = await self.run_agent(agent)

                    # ê²°ê³¼ ì •ê·œí™”: Message -> dict
                    if isinstance(task_result, Message):
                        result_text = task_result.text if hasattr(task_result, "text") else str(task_result)
                        task_result = {
                            "task_id": task_id,
                            "status": "completed",
                            "task_description": task_title,
                            "result": result_text,
                        }

                    # ì‚°ì¶œë¬¼ ì €ìž¥
                    for output in next_task.get('outputs', []):
                        self.task_outputs[output] = task_result.get('result', 'Task completed') if isinstance(task_result, dict) else 'Task completed'
                    
                    # ì‹¤í–‰ ê²°ê³¼ì— ì‚°ì¶œë¬¼ ì •ë³´ ì¶”ê°€
                    if isinstance(task_result, dict):
                        task_result['task_outputs'] = next_task.get('outputs', [])
                        task_result['outputs_completed'] = True if task_result.get('status') == 'completed' else False
                    
                    self.completed_tasks.add(task_id)
                    logger.info(f"Task {task_id} completed successfully")

                except Exception as e:
                        logger.error(f"Error executing task {task_id}: {e}")
                        task_result = {
                            "task_id": task_id,
                            "status": "failed",
                            "error": str(e),
                            "task_outputs": next_task.get('outputs', []),
                            "outputs_completed": False,
                            "execution_time": 0
                        }

                self.execution_history.append(task_result)

                self.execution_history_output()
                
                # A2A Criticì— ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„
                critic_data = self.prepare_critic_data(task_result, execution_plan)
                final_result = {
                    "status": "task_completed",
                    "executed_task": task_result,
                    "critic_data": critic_data,
                    "completed_tasks": list(self.completed_tasks),
                    "total_tasks": len(work_breakdown),
                    "task_outputs": self.task_outputs,
                    "remaining_tasks": len(work_breakdown) - len(self.completed_tasks)
                }
            #----------------------------------------------------


            result_json = json.dumps(final_result, ensure_ascii=False, indent=2)
            return Message(
                text=result_json,
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI,
            )
            
        except Exception as e:
            error_msg = f"Agent plan execution error: {str(e)}"
            logger.error(error_msg)
            return Message(
                text=error_msg,
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI,
            )

    def parse_execution_plan(self, plan_message: Message) -> Dict[str, Any]:
        """ì‹¤í–‰ ê³„íš ë©”ì‹œì§€ë¥¼ íŒŒì‹±"""
        try:
            if hasattr(plan_message, 'text'):
                plan_text = plan_message.text
            else:
                plan_text = str(plan_message)
            
            execution_plan = json.loads(plan_text)
            return execution_plan
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse execution plan JSON: {e}")
            raise ValueError(f"Invalid execution plan format: {e}")
        except Exception as e:
            logger.error(f"Error parsing execution plan: {e}")
            raise

    def get_next_executable_task(self, work_breakdown: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """ì˜ì¡´ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒì— ì‹¤í–‰ ê°€ëŠ¥í•œ ìž‘ì—… í•˜ë‚˜ë¥¼ ë°˜í™˜ (ìˆœì°¨ ì‹¤í–‰)"""
        for task in work_breakdown:
            task_id = task.get('id')
            
            if task_id in self.completed_tasks:
                continue
                
            dependencies = task.get('dependencies', [])
            dependencies_met = all(dep_id in self.completed_tasks for dep_id in dependencies)
            
            if dependencies_met:
                return task
        
        return None

    async def validate_output_exists(self, task: Dict[str, Any]) -> bool:
        """execution_historyë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìž‘ì—…ì˜ ì‚°ì¶œë¬¼ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ê²€ì¦"""
        try:
            # ê²€ì¦ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
            if not getattr(self, 'enable_output_validation', True):
                logger.info(f"Output validation disabled, proceeding with execution for task '{task.get('title')}'")
                return False
                
            task_outputs = task.get('outputs', [])
            if not task_outputs:
                # ì‚°ì¶œë¬¼ì´ ì •ì˜ë˜ì§€ ì•Šì€ ìž‘ì—…ì€ ì¤‘ë³µ ì‹¤í–‰ í—ˆìš©
                logger.info(f"Task '{task.get('title')}' has no defined outputs, proceeding with execution")
                return False
            
            # execution_historyì—ì„œ ì™„ë£Œëœ ì‚°ì¶œë¬¼ë“¤ ìˆ˜ì§‘
            completed_outputs = set()
            for history_item in self.execution_history:
                if history_item.get('outputs_completed', False):
                    completed_outputs.update(history_item.get('task_outputs', []))
            
            # í˜„ìž¬ ìž‘ì—…ì˜ ëª¨ë“  ì‚°ì¶œë¬¼ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            required_outputs = set(task_outputs)
            missing_outputs = required_outputs - completed_outputs
            
            if not missing_outputs:
                logger.info(f"Task '{task.get('title')}' outputs {task_outputs} already completed, skipping execution")
                return True
            else:
                logger.info(f"Task '{task.get('title')}' missing outputs {list(missing_outputs)}, proceeding with execution")
            return False
            
        except Exception as e:
            logger.error(f"Error validating output existence: {e}")
            logger.info(f"Falling back to assume output doesn't exist for task '{task.get('title')}'")
            return False

    async def execute_builtin_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ë‚´ìž¥ ê¸°ëŠ¥ìœ¼ë¡œ ìž‘ì—… ì‹¤í–‰ - a2a-agent.pyì˜ execute_task_directly ë°©ì‹ ì‚¬ìš©"""
        task_id = task.get('id')
        task_title = task.get('title', 'Unknown Task')
        
        logger.info(f"Executing builtin task {task_id}: {task_title}")
        
        # a2a-agent.pyì˜ execute_task_directly ë¡œì§ ì ìš©
        try:
            # Tool ížŒíŠ¸ê°€ ì—¬ëŸ¬ ë„êµ¬ì™€ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ í•­ìƒ ë¹„í™œì„±í™”
            if hasattr(self, "tool_name"):
                self.tool_name = ""
            if hasattr(self, "tool_description"):
                self.tool_description = ""

            # ìž‘ì—… ë‹¨ìœ„ ìž…ë ¥ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (agent.pyì˜ input_valueì™€ ìœ ì‚¬í•˜ê²Œ ë‹¨ì¼ ë¬¸ìžì—´)
            inputs = ", ".join(task.get("inputs", []))
            outputs = ", ".join(task.get("outputs", []))
            description = task.get("description", "")
            task_prompt = f"Task: {task_title}\nDescription: {description}\nInputs: {inputs}\nExpected Outputs: {outputs}".strip()

            # 1) Toolì´ ì—°ê²°ë˜ì–´ ìžˆìœ¼ë©´ Tool ìš°ì„  ì‚¬ìš©
            has_tools = hasattr(self, "tools") and isinstance(self.tools, list) and len(self.tools) > 0
            if has_tools:
                logger.info(f"Tools found, executing with tools : {self.tools}")
                try:
                    # ì—¬ëŸ¬ ë„êµ¬ ì‚¬ìš© í—ˆìš©í•˜ë˜, ë‹¨ì¼-íˆ´ ížŒíŠ¸ëŠ” ë¹„í™œì„±í™”í•˜ì—¬ ê²€ì¦ ì¶©ëŒ ë°©ì§€
                    if hasattr(self, "tool_name"):
                        self.tool_name = ""
                    if hasattr(self, "tool_description"):
                        self.tool_description = ""

                    # ê¸°ì¡´ ë„êµ¬ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ Agent ì‹¤í–‰ (ë³µìˆ˜ ë„êµ¬ ì‚¬ìš© í—ˆìš©)
                    self.set(
                        llm=self.llm,
                        tools=self.tools,
                        chat_history=getattr(self, "chat_history", []),
                        input_value=task_prompt,
                        system_prompt=getattr(self, "system_prompt", ""),
                    )
                    agent = self.create_agent_runnable()
                    agent_result_msg: Message = await self.run_agent(agent)
                    result_text = agent_result_msg.text if hasattr(agent_result_msg, "text") else str(agent_result_msg)

                    logger.info(f"-- Tools agent result: {result_text}")

                    return {
                        "task_id": task_id,
                        "execution_method": "tools_agent",
                        "status": "completed",
                        "task_description": task_title,
                        "user_input": task_prompt,
                        "result": result_text,
                    }
                except Exception as tool_err:
                    logger.warning(f"Tool execution failed, falling back to LLM: {tool_err}")
            else:
                logger.info("No tools found, executing with LLM")

            # 2) Toolì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°: LLM ê¸°ë°˜ ì¼ë°˜ ì²˜ë¦¬
            return await self.handle_general_task(task, task_prompt)
                
        except Exception as e:
            logger.error(f"Error executing builtin task {task_id}: {e}")
            return {
                "task_id": task_id,
                "status": "failed",
                "error": str(e),
                "execution_time": 0
            }

    async def handle_general_task(self, task: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ ìž‘ì—… ì²˜ë¦¬"""
        logger.info("ì¼ë°˜ ìž‘ì—… ì‹¤í–‰")
        
        # ê¸°ë³¸ì ì¸ ìž‘ì—… ì²˜ë¦¬
        task_description = task.get("title", "ì¼ë°˜ ìž‘ì—…")
        
        # LLMì´ ìžˆëŠ” ê²½ìš° LLMì„ ì‚¬ìš©
        if hasattr(self, 'llm') and self.llm is not None:
            try:

                verbose_prefix = f"**ì‘ë‹µì€ ì£¼ì–´ì§„ taskì˜ outputsì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë§Œ ë‹¤ìŒ json ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.**\në°˜í™˜í˜•ì‹\n{{'output ìš”ì†Œ':'output ê°’', ... }}\n\n" if not self.verbose else ""

                prompt = f"""{verbose_prefix}
                
                ë‹¤ìŒ ìž‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

ìž‘ì—…: {task_description}
ì‚¬ìš©ìž ìž…ë ¥: {user_input}

ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ìž‘ì—…ì„ ì™„ë£Œí•˜ê³  ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
                
                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                result_content = response.content if hasattr(response, 'content') else str(response)
                
                # verbose ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° JSON íŒŒì‹± ì ìš©
                if not self.verbose:
                    parsed_result = self._parse_json_from_text(result_content)
                    if isinstance(parsed_result, dict) and "error" not in parsed_result:
                        result_content = parsed_result
                
                logger.info(f"Basic general task result: {result_content}")
                
                return {
                    "task_id": task["id"],
                    "execution_method": "llm_general",
                    "status": "completed",
                    "task_description": task_description,
                    "user_input": user_input,
                    "result": f"ðŸ”§ ìž‘ì—…: {task_description}\nðŸ“ ìž…ë ¥: {user_input}\n\nâœ… ê²°ê³¼:\n{result_content}"
                }
            except Exception as e:
                logger.error(f"LLM ì¼ë°˜ ìž‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # LLMì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        result_content = f"'{task_description}' ìž‘ì—…ì„ '{user_input}' ìž…ë ¥ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë” ì •êµí•œ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” LLM ëª¨ë¸ì´ë‚˜ ì „ìš© ë„êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        

        logger.info(f"Basic general task result: {result_content}")
        
        return {
            "task_id": task["id"],
            "execution_method": "basic_general",
            "status": "completed",
            "task_description": task_description,
            "user_input": user_input,
            "result": f"ðŸ”§ ìž‘ì—…: {task_description}\nðŸ“ ìž…ë ¥: {user_input}\n\nâœ… ê¸°ë³¸ ì²˜ë¦¬ ê²°ê³¼:\n{result_content}"
        }

    async def delegate_to_agent(self, task: Dict[str, Any], agent_info: Dict[str, Any]) -> Dict[str, Any]:
        """ì™¸ë¶€ ì—ì´ì „íŠ¸ì— ìž‘ì—… ìœ„ìž„"""
        task_id = task.get('id')
        task_title = task.get('title', 'Unknown Task')
        
        logger.info(f"Delegating task {task_id} to agent: {agent_info.get('name', 'Unknown')}")
        
        try:
            agent_url = agent_info.get('url', agent_info.get('endpoint'))
            if not agent_url:
                raise ValueError("Agent URL not found")
            
            # verbose ëª¨ë“œì— ë”°ë¼ í…ìŠ¤íŠ¸ ì•žë¶€ë¶„ ê²°ì •
            verbose_prefix = f"**ì‘ë‹µì€ ì£¼ì–´ì§„ taskì˜ outputsì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë§Œ ë‹¤ìŒ json ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.**\në°˜í™˜í˜•ì‹\n{{'output ìš”ì†Œ':'output ê°’', ... }}\n\n" if not self.verbose else ""
            
            a2a_rpc_payload = {
                "jsonrpc": "2.0",
                "id": task["id"],
                "method": "invoke",
                "params": {
                    "message": {
                        "message_id": task["id"],
                        "role": "user",
                        "parts": [
                            {
                                "kind": "text",
                                "text": f"{verbose_prefix}Task: {task['title']}\nDescription: {task.get('description', '')}\nInputs: {', '.join(task.get('inputs', []))}\nExpected Outputs: {', '.join(task.get('outputs', []))}"
                            }
                        ]
                    },
                    "stream": False  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
                }
            }

            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json",
                "User-Agent": "A2A-Agent-Component/1.0"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    agent_url,
                    json=a2a_rpc_payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"Task {task_id} delegated successfully")
                        extracted_data = self.extract_text_from_agent_response(result)

                        if not extracted_data:
                            raise Exception("Agent response could not be parsed")

                        response_text = extracted_data["response_text"] 
                        if not self.verbose and isinstance(response_text, str):
                            response_text = self._parse_json_from_text(response_text)
                        
                        return {
                            "task_id": task["id"],
                            "agent_id": agent_info.get('name', 'Unknown'),
                            "status": "completed",
                            "timestamp": "2024-01-01T00:00:00Z",
                            "session_id": extracted_data["session_id"],
                            "input_text": extracted_data["input_text"],
                            "response_text": response_text
                        }
                    else:
                        error_text = await response.text()
                        raise Exception(f"Agent returned status {response.status}: {error_text}")
                        
        except Exception as e:
            logger.error(f"Error delegating task {task_id}: {e}")
            return {
                "task_id": task_id,
                "status": "failed",
                "error": str(e),
                "execution_time": 0
            }

    def extract_text_from_agent_response(self, agent_response: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """A2A ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        try:
            # agent_responseê°€ ì´ë¯¸ dictì¸ ê²½ìš°
            if isinstance(agent_response, dict):
                obj = agent_response
            # agent_responseê°€ ë¬¸ìžì—´ì¸ ê²½ìš° JSON íŒŒì‹±
            elif isinstance(agent_response, str):
                if agent_response.strip().startswith('{'):
                    obj = json.loads(agent_response)
                else:
                    logger.warning("Agent response is not a valid JSON string")
                    return None
            else:
                logger.warning(f"Unexpected agent_response type: {type(agent_response)}")
                return None
            
            # JSON êµ¬ì¡°ì—ì„œ ì¤‘ì²©ëœ JSON ë¬¸ìžì—´ íŒŒì‹±
            obj = self._parse_nested_json_strings(obj)
            
            # parts í•„ë“œë“¤ ì°¾ê¸°
            parts = self.find_parts(obj)
            
            if len(parts) == 0:
                logger.warning("No message fields found in agent response")
                return None

            #logger.info(f"agent_response parts: {parts[0]}") 
            
            # ì•ˆì „í•œ ë°ì´í„° ì¶”ì¶œ
            try:
                session_id = self._extract_session_id(parts)
                input_text = self._extract_input_text(parts)
                response_text = self._extract_response_text(parts)                
            except Exception as e:
                logger.error(f"Error extracting data from parts: {e}")
                logger.error(f"Parts structure: {parts}")
                return None 
            
            if not response_text:
                logger.warning("No meaningful text content found in messages")
                return None
               
            return {
                "session_id": session_id,
                "input_text": input_text,
                "response_text": response_text
            }
        except Exception as e:
            logger.error(f"Error extracting text from agent response: {e}")
            return None

    def _parse_nested_json_strings(self, obj):
        """ì¤‘ì²©ëœ JSON ë¬¸ìžì—´ì„ ìž¬ê·€ì ìœ¼ë¡œ íŒŒì‹±"""
        if isinstance(obj, dict):
            result = {}
            for key, value in obj.items():
                if isinstance(value, str) and value.strip().startswith('{'):
                    try:
                        result[key] = self._parse_nested_json_strings(json.loads(value))
                    except json.JSONDecodeError:
                        result[key] = value
                else:
                    result[key] = self._parse_nested_json_strings(value)
            return result
        elif isinstance(obj, list):
            return [self._parse_nested_json_strings(item) for item in obj]
        else:
            return obj

    def _extract_input_text(self, parts: list) -> str:
        """partsì—ì„œ input_valueë¥¼ ìž¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
        if not parts:
            return "unknown"
        
        result = self._find_value_recursive(parts, "input_value", "unknown")
        return result if result != "unknown" else "unknown"

    def _extract_response_text(self, parts: list) -> str:
        """partsì—ì„œ ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ ìž¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
        if not parts:
            return None
        
        # message.data.text ê²½ë¡œë¥¼ ë”°ë¼ ì°¾ê¸°
        result = self._find_value_recursive(parts, "data", None)
        
        text = ""
        if  result:
            try:
                text=result.get("text") if isinstance(result, dict) else ""
            except Exception:
                text = ""

        return text

    def _parse_json_from_text(self, text: str) -> Any:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON êµ¬ì„± ì •ë³´ë§Œ ì¶”ë ¤ì„œ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìž¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜"""
        import re
        
        # JSON ê°ì²´ íŒ¨í„´ ì°¾ê¸° (ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¶€ë¶„)
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text)
        if json_match:
            json_str = json_match.group(0)
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse JSON from text: {json_str}")
                return {"error": "JSON parsing failed", "raw_text": text}
        else:
            logger.warning(f"No JSON pattern found in text: {text}")
            return {"error": "No JSON pattern found", "raw_text": text}
        
    def find_parts(self, obj: Dict[str, Any]) -> list[Dict[str, Any]]:
        """
        JSON(dict/list) êµ¬ì¡° ë‚´ë¶€ë¥¼ ìž¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ 
        'parts' í•„ë“œë¡œ ì§€ì •ëœ ë‚´ìš©ì„ ëª¨ë‘ ì°¾ì•„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        """
        results = []

        if isinstance(obj, dict):
            # í˜„ìž¬ dictì— 'parts' í‚¤ê°€ ìžˆìœ¼ë©´ ì¶”ê°€
            if "parts" in obj:
                parts_content = obj["parts"]
                # partsê°€ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì´ë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€, ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if isinstance(parts_content, list):
                    results.extend(parts_content)
                else:
                    results.append(parts_content)

            # ìž¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ê°’ë“¤ì„ íƒìƒ‰
            for value in obj.values():
                results.extend(self.find_parts(value))

        elif isinstance(obj, list):
            # ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ ìž¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
            for item in obj:
                results.extend(self.find_parts(item))

        return results

    def _find_value_recursive(self, obj: Any, target_key: str, default_value: Any = None) -> Any:
        """
        ì¤‘ì²©ëœ dict/list êµ¬ì¡°ì—ì„œ íŠ¹ì • í‚¤ì˜ ê°’ì„ ìž¬ê·€ì ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜
        
        Args:
            obj: íƒìƒ‰í•  ê°ì²´ (dict, list, ë˜ëŠ” ê¸°íƒ€)
            target_key: ì°¾ì„ í‚¤ ì´ë¦„
            default_value: ì°¾ì§€ ëª»í–ˆì„ ë•Œ ë°˜í™˜í•  ê¸°ë³¸ê°’
            
        Returns:
            ì°¾ì€ ê°’ ë˜ëŠ” ê¸°ë³¸ê°’
        """
        if isinstance(obj, dict):
            # í˜„ìž¬ dictì— íƒ€ê²Ÿ í‚¤ê°€ ìžˆìœ¼ë©´ ë°˜í™˜
            if target_key in obj:
                return obj[target_key]
            
            # ëª¨ë“  ê°’ë“¤ì„ ìž¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
            for value in obj.values():
                result = self._find_value_recursive(value, target_key, default_value)
                if result is not default_value:
                    return result
                    
        elif isinstance(obj, list):
            # ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ íƒìƒ‰
            for item in obj:
                result = self._find_value_recursive(item, target_key, default_value)
                if result is not default_value:
                    return result
        
        return default_value

    def _extract_session_id(self, parts: list) -> str:
        """partsì—ì„œ session_idë¥¼ ìž¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
        if not parts:
            return "unknown"
        
        result = self._find_value_recursive(parts, "session_id", "unknown")
        return result if result != "unknown" else "unknown"

    def prepare_critic_data(self, task_result: Dict[str, Any], 
                           current_plan: Dict[str, Any]) -> Dict[str, Any]:
        """A2A Criticì— ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„"""
        logger.info("Preparing data for A2A Critic")
        
        try:
            # task_resultì—ì„œ response_text ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            response_text = task_result.get("response_text", "{}")
            if isinstance(response_text, str):
                try:
                    parsed_response = json.loads(response_text)
                except json.JSONDecodeError:
                    logger.warning(f"Failed to parse response_text as JSON: {response_text}")
                    parsed_response = {"raw_text": response_text}
            else:
                parsed_response = response_text if response_text else {}
            
            critique_data = {
                "execution_results": [task_result],
                "current_plan": current_plan,
                "task_outputs": self.task_outputs,
                "task_result": parsed_response,
                "completed_tasks": list(self.completed_tasks),
                "total_tasks": len(current_plan.get('work_breakdown', [])),
                "progress": f"{len(self.completed_tasks)}/{len(current_plan.get('work_breakdown', []))}"
            }
            
            logger.info(f"Critic data structure prepared successfully")
            return critique_data
            
        except Exception as e:
            logger.error(f"Error preparing critic data: {e}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "execution_results": [task_result],
                "current_plan": current_plan,
                "task_outputs": self.task_outputs,
                "task_result": {},
                "completed_tasks": list(self.completed_tasks),
                "total_tasks": len(current_plan.get('work_breakdown', [])),
                "progress": f"{len(self.completed_tasks)}/{len(current_plan.get('work_breakdown', []))}",
                "error": f"Critic data preparation failed: {str(e)}"
            }

    def all_tasks_completed(self, work_breakdown: List[Dict[str, Any]]) -> bool:
        """ëª¨ë“  ìž‘ì—…ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        all_task_ids = {task.get('id') for task in work_breakdown}
        return all_task_ids.issubset(self.completed_tasks)

    def execution_history_output(self) -> Message:
        """ì‹¤í–‰ ì´ë ¥ì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            history_data = {
                "execution_history": self.execution_history,
                "completed_tasks": list(self.completed_tasks),
                "task_outputs": self.task_outputs,
                "total_executions": len(self.execution_history),
                "completion_rate": len(self.completed_tasks) / max(len(self.execution_history), 1) * 100,
                "last_updated": "í˜„ìž¬ ì‹œì "
            }
            
            history_json = json.dumps(history_data, ensure_ascii=False, indent=2)
            
            return Message(
                text=f"{history_json}",
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI,
            )
            
        except Exception as e:
            error_msg = f"Error retrieving execution history: {str(e)}"
            logger.error(error_msg)
            return Message(
                text=error_msg,
                sender=MESSAGE_SENDER_AI,
                sender_name=MESSAGE_SENDER_NAME_AI,
            )

    async def get_memory_data(self):
        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.
        messages = (
            await MemoryComponent(**self.get_base_args())
            .set(session_id=self.graph.session_id, order="Ascending", n_messages=self.n_messages)
            .retrieve_messages()
        )
        return [
            message for message in messages if getattr(message, "id", None) != getattr(self.input_value, "id", None)
        ]

    def get_llm(self):
        if not isinstance(self.agent_llm, str):
            return self.agent_llm, None

        try:
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if not provider_info:
                msg = f"Invalid model provider: {self.agent_llm}"
                raise ValueError(msg)

            component_class = provider_info.get("component_class")
            display_name = component_class.display_name
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix", "")

            return self._build_llm_model(component_class, inputs, prefix), display_name

        except Exception as e:
            logger.error(f"Error building {self.agent_llm} language model: {e!s}")
            msg = f"Failed to initialize language model: {e!s}"
            raise ValueError(msg) from e

    def _build_llm_model(self, component, inputs, prefix=""):
        model_kwargs = {}
        for input_ in inputs:
            if hasattr(self, f"{prefix}{input_.name}"):
                model_kwargs[input_.name] = getattr(self, f"{prefix}{input_.name}")
        return component.set(**model_kwargs).build_model()

    def set_component_params(self, component):
        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
        if provider_info:
            inputs = provider_info.get("inputs")
            prefix = provider_info.get("prefix")
            model_kwargs = {input_.name: getattr(self, f"{prefix}{input_.name}") for input_ in inputs}

            return component.set(**model_kwargs)
        return component

    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:
        """Delete specified fields from build_config."""
        for field in fields:
            build_config.pop(field, None)

    def update_input_types(self, build_config: dotdict) -> dotdict:
        """Update input types for all fields in build_config."""
        for key, value in build_config.items():
            if isinstance(value, dict):
                if value.get("input_types") is None:
                    build_config[key]["input_types"] = []
            elif hasattr(value, "input_types") and value.input_types is None:
                value.input_types = []
        return build_config

    async def update_build_config(
        self, build_config: dotdict, field_value: str, field_name: str | None = None
    ) -> dotdict:
        # Iterate over all providers in the MODEL_PROVIDERS_DICT
        # Existing logic for updating build_config
        if field_name in ("agent_llm",):
            build_config["agent_llm"]["value"] = field_value
            provider_info = MODEL_PROVIDERS_DICT.get(field_value)
            if provider_info:
                component_class = provider_info.get("component_class")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call the component class's update_build_config method
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )

            provider_configs: dict[str, tuple[dict, list[dict]]] = {
                provider: (
                    MODEL_PROVIDERS_DICT[provider]["fields"],
                    [
                        MODEL_PROVIDERS_DICT[other_provider]["fields"]
                        for other_provider in MODEL_PROVIDERS_DICT
                        if other_provider != provider
                    ],
                )
                for provider in MODEL_PROVIDERS_DICT
            }
            if field_value in provider_configs:
                fields_to_add, fields_to_delete = provider_configs[field_value]

                # Delete fields from other providers
                for fields in fields_to_delete:
                    self.delete_fields(build_config, fields)

                # Add provider-specific fields
                if field_value == "OpenAI" and not any(field in build_config for field in fields_to_add):
                    build_config.update(fields_to_add)
                else:
                    build_config.update(fields_to_add)
                # Reset input types for agent_llm
                build_config["agent_llm"]["input_types"] = []
            elif field_value == "Custom":
                # Delete all provider fields
                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)
                # Update with custom component
                custom_component = DropdownInput(
                    name="agent_llm",
                    display_name="Language Model",
                    options=[*sorted(MODEL_PROVIDERS), "Custom"],
                    value="Custom",
                    real_time_refresh=True,
                    input_types=["LanguageModel"],
                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]
                    + [{"icon": "brain"}],
                )
                build_config.update({"agent_llm": custom_component.to_dict()})
            # Update input types for all fields
            build_config = self.update_input_types(build_config)

            # Validate required keys
            default_keys = [
                "code",
                "_type",
                "agent_llm",
                "tools",
                "input_value",
                "add_current_date_tool",
                "system_prompt",
                "agent_description",
                "max_iterations",
                "handle_parsing_errors",
                "verbose",
            ]
            missing_keys = [key for key in default_keys if key not in build_config]
            if missing_keys:
                msg = f"Missing required keys in build_config: {missing_keys}"
                raise ValueError(msg)
        if (
            isinstance(self.agent_llm, str)
            and self.agent_llm in MODEL_PROVIDERS_DICT
            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS
        ):
            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)
            if provider_info:
                component_class = provider_info.get("component_class")
                component_class = self.set_component_params(component_class)
                prefix = provider_info.get("prefix")
                if component_class and hasattr(component_class, "update_build_config"):
                    # Call each component class's update_build_config method
                    # remove the prefix from the field_name
                    if isinstance(field_name, str) and isinstance(prefix, str):
                        field_name = field_name.replace(prefix, "")
                    build_config = await update_component_build_config(
                        component_class, build_config, field_value, "model_name"
                    )
        return dotdict({k: v.to_dict() if hasattr(v, "to_dict") else v for k, v in build_config.items()})

